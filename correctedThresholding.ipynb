{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "correctedThresholding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOG2KTq7dydqazWkCd6+MOs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mefy-Aruna/DiabetesApp/blob/main/correctedThresholding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtF0fMGua_UF"
      },
      "source": [
        "# Importing filtered data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNun1_4-R_pc",
        "outputId": "e2648b11-c28c-47a5-cb01-2d93ea71b66f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import pandas as pd\n",
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from fancyimpute import IterativeImputer\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKZUrP6zTTBr",
        "outputId": "e17421ff-ba2e-4b50-a617-87bc30040b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "df = pd.read_excel(r'filtered.xlsx')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-444633952195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'filtered.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'filtered.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5y69wt4UnWM"
      },
      "source": [
        "df.to_csv('filtered.csv',index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg_l-YBgU8CD",
        "outputId": "cd822c64-c282-48d9-e86c-b8478ba34324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "data = pd.read_csv(r'filtered.csv')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>glucose</th>\n",
              "      <th>trigs</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>Diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>11.77</td>\n",
              "      <td>118.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.7</td>\n",
              "      <td>110.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2.37</td>\n",
              "      <td>172.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.3</td>\n",
              "      <td>114.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>168.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.1</td>\n",
              "      <td>108.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>3.74</td>\n",
              "      <td>144.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.6</td>\n",
              "      <td>134.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>104.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.9</td>\n",
              "      <td>130.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>11.43</td>\n",
              "      <td>171.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>39.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>136.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>33.20</td>\n",
              "      <td>197.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>6.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.5</td>\n",
              "      <td>128.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.7</td>\n",
              "      <td>150.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>4.16</td>\n",
              "      <td>223.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>5.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age   bmi  waist_cm  ...  trigs  a1c  glucose.1  Diabetes \n",
              "0          1   21  18.2      82.0  ...   54.0  5.0       88.0        0.0\n",
              "1          0   21  25.9      93.7  ...   83.0  5.2       88.0        0.0\n",
              "2          0   21  29.5     102.3  ...  256.0  5.1        NaN        0.0\n",
              "3          0   21  17.9      69.1  ...   57.0  5.1       95.0        0.0\n",
              "4          0   21  30.6     101.6  ...   70.0  6.0       95.0        0.0\n",
              "...      ...  ...   ...       ...  ...    ...  ...        ...        ...\n",
              "5201       0   77  32.8     115.9  ...  130.0  6.5      134.0        1.0\n",
              "5202       0   77  32.9     122.2  ...    NaN  6.2       98.0        0.0\n",
              "5203       0   77  39.2       NaN  ...  169.0  6.3        NaN        1.0\n",
              "5204       1   77  36.5     119.5  ...   67.0  6.2      103.0        0.0\n",
              "5205       1   77  34.8     104.7  ...  117.0  5.7        NaN        1.0\n",
              "\n",
              "[5206 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQTW2s0AeWY_"
      },
      "source": [
        "y = data.iloc[:, 12].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5kVrMStbJS2"
      },
      "source": [
        "# Imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75-6Xvj6bO8U"
      },
      "source": [
        "from fancyimpute import IterativeImputer as MICE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xKXRPUWbwyS"
      },
      "source": [
        "from fancyimpute import IterativeImputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuTDuWTHbyDj",
        "outputId": "c0fd232e-be00-476a-f8b3-c6c301a17104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "pip install mice"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mice\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/d4/1eb8e7d9fb3c2341fd9efd1514bc81439dd20ea987548f438c4a79d92c99/mice-0.0.1a0.tar.gz\n",
            "Building wheels for collected packages: mice\n",
            "  Building wheel for mice (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mice: filename=mice-0.0.1a0-cp36-none-any.whl size=1045 sha256=3c76b28ad2685e1b89763c6bf4abb929d58c089eaff3474feade319998b3a5e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e7/4f/1b0c52cfdb6dc95dd0ba1459459f8e4ed33cab25eccdd78d65\n",
            "Successfully built mice\n",
            "Installing collected packages: mice\n",
            "Successfully installed mice-0.0.1a0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdGRXzlxb6uw",
        "outputId": "98845baf-8b3b-414b-f60d-298d1b3205d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        }
      },
      "source": [
        "pip install fancyimpute"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fancyimpute in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (2.3.0)\n",
            "Requirement already satisfied: knnimpute in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (0.1.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (1.18.5)\n",
            "Requirement already satisfied: cvxpy>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (1.0.31)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (0.22.2.post1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (2.4.3)\n",
            "Requirement already satisfied: np-utils in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (0.5.12.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fancyimpute) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (0.35.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->fancyimpute) (2.10.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0.6->fancyimpute) (0.6.1)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0.6->fancyimpute) (2.1.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0.6->fancyimpute) (0.70.10)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0.6->fancyimpute) (2.0.7.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->fancyimpute) (0.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->fancyimpute) (3.13)\n",
            "Requirement already satisfied: future>=0.16 in /usr/local/lib/python3.6/dist-packages (from np-utils->fancyimpute) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow->fancyimpute) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (2.23.0)\n",
            "Requirement already satisfied: dill>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from multiprocess->cvxpy>=1.0.6->fancyimpute) (0.3.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->fancyimpute) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjeAAG4lcB7Z"
      },
      "source": [
        "from fancyimpute import IterativeImputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uMio2fOcDlT"
      },
      "source": [
        "mice_impute = IterativeImputer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUNOqQZgcRws",
        "outputId": "6d22d880-7e76-4954-ee70-48c692804a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mice_data = mice_impute.fit_transform(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRAj0dxucZ6_",
        "outputId": "75aea03c-73aa-4ec3-efc2-e2f88829c2f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "mice_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.        ,  21.        ,  18.2       , ...,   5.        ,\n",
              "         88.        ,   0.        ],\n",
              "       [  0.        ,  21.        ,  25.9       , ...,   5.2       ,\n",
              "         88.        ,   0.        ],\n",
              "       [  0.        ,  21.        ,  29.5       , ...,   5.1       ,\n",
              "         94.16074483,   0.        ],\n",
              "       ...,\n",
              "       [  0.        ,  77.        ,  39.2       , ...,   6.3       ,\n",
              "        106.72079006,   1.        ],\n",
              "       [  1.        ,  77.        ,  36.5       , ...,   6.2       ,\n",
              "        103.        ,   0.        ],\n",
              "       [  1.        ,  77.        ,  34.8       , ...,   5.7       ,\n",
              "         96.8663047 ,   1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TuNx14Qcco8",
        "outputId": "cad66f10-7d0b-41c3-92ca-45c8af4d834e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "data_n = pd.DataFrame(mice_data)\n",
        "data_n.to_csv(\"miceDataset.csv\", index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4b9cba19a92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmice_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"miceDataset.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mice_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vaw6SswFci3o"
      },
      "source": [
        "data = pd.read_csv(r'miceDataset.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF37RAmlXEd8"
      },
      "source": [
        "data1 = pd.read_csv(r'miceDataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsxvtK0Dcld9",
        "outputId": "279f8406-edc1-41ab-da0c-84160b290b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>glucose</th>\n",
              "      <th>trigs</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>Diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>11.77</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.700000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>60.00000</td>\n",
              "      <td>2.37</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.300000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>72.00000</td>\n",
              "      <td>3.73</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>94.160745</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>3.74</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.600000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>3.13</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.900000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>11.43</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.200000</td>\n",
              "      <td>140.666578</td>\n",
              "      <td>76.05274</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>207.939424</td>\n",
              "      <td>91.927995</td>\n",
              "      <td>205.687652</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>39.2</td>\n",
              "      <td>128.090281</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>33.20</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>6.3</td>\n",
              "      <td>106.720790</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.500000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>74.00000</td>\n",
              "      <td>3.92</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.700000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>78.00000</td>\n",
              "      <td>4.16</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>5.7</td>\n",
              "      <td>96.866305</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age   bmi    waist_cm  ...       trigs  a1c   glucose.1  Diabetes \n",
              "0          1   21  18.2   82.000000  ...   54.000000  5.0   88.000000        0.0\n",
              "1          0   21  25.9   93.700000  ...   83.000000  5.2   88.000000        0.0\n",
              "2          0   21  29.5  102.300000  ...  256.000000  5.1   94.160745        0.0\n",
              "3          0   21  17.9   69.100000  ...   57.000000  5.1   95.000000        0.0\n",
              "4          0   21  30.6  101.600000  ...   70.000000  6.0   95.000000        0.0\n",
              "...      ...  ...   ...         ...  ...         ...  ...         ...        ...\n",
              "5201       0   77  32.8  115.900000  ...  130.000000  6.5  134.000000        1.0\n",
              "5202       0   77  32.9  122.200000  ...  205.687652  6.2   98.000000        0.0\n",
              "5203       0   77  39.2  128.090281  ...  169.000000  6.3  106.720790        1.0\n",
              "5204       1   77  36.5  119.500000  ...   67.000000  6.2  103.000000        0.0\n",
              "5205       1   77  34.8  104.700000  ...  117.000000  5.7   96.866305        1.0\n",
              "\n",
              "[5206 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5rKM18Sdsz2"
      },
      "source": [
        "# PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAmAPI_VbPk",
        "outputId": "61b637c2-e38f-4bfd-ad8d-f28e4dce7f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = data.iloc[:, 0:12].values\n",
        "y = data.iloc[:, 12].values\n",
        "x\n",
        "y"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNDpCTFDhtpL"
      },
      "source": [
        "ynew=[]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKBDMnfbhkVe",
        "outputId": "98fcb542-cbac-4dc4-a542-5f404d001b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y:\n",
        "  if i>0.7:\n",
        "    add=1\n",
        "    ynew.append(add)\n",
        "  elif i<0.7:\n",
        "    add=0\n",
        "    ynew.append(add)\n",
        "\n",
        "ynew\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_XV2oo6AvhO"
      },
      "source": [
        "#gender\tage Trigs\tbmi\twaist_cm\tsys_bp\tdia_bp\talb_cr_ratio\tt_chol\tglucose\ta1c\tglucose.1\tDiabetes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCwPdtH0CocU"
      },
      "source": [
        "Gender: prediabetes=47.8% (of 226), Diabetes = 52% (of 275)\n",
        "Age: prediabetes = (60)34-85, Diabetes= (64)24-84yrs\n",
        "Trigs: Normal = 0.1-0.7, Pre=(1.3) 0.5-5.3, Diabetes =(1.5) 0.4-7.7\n",
        "BMI:normal = 28 ± 3, pre= \t29 ± 1\n",
        "Waist_cm:normal = 89 ± 5, pre=\t99 ± 2\n",
        "sys_bp:normal=120 ± 4,pre=\t131 ± 7\n",
        "dia_bp:normal =74 ± 1,\t77 ± 4\n",
        "(serum)glucose.1:pre=140-200\n",
        "(serum) glucose: normal=<140, pre=140-199, diabetes> 200\n",
        "\n",
        "alb_cr_ratio:pre=9.6 (2.3–730.7),dia =\t15.8 (2.4–1,242.7)\n",
        "t_chol:Normal = 2.6–5.2,pre=(5.4) 2.9–8.9, (4.6)2.5–7.5\t\n",
        "(fasting)glucose:Norm=3.9–5.5,Pre=5.9(4.2–6.9),Dia=7.7(3.6–21.3)\n",
        "fasting glucose: normal=95 ± 10,prediabetes:\t101 ± 2\n",
        "fasting = normal < 100, pre=100-125, diabetes>126\n",
        "A1C:normal= 4-5.6, pre=(5.7) 4.5–8.0, dia=(7)4.5–8.0\n",
        "\n",
        "https://www.mayoclinic.org/diseases-conditions/diabetes/diagnosis-treatment/drc-20371451#:~:text=A%20fasting%20blood%20sugar%20level,Oral%20glucose%20tolerance%20test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJDzNR4BS7Ur"
      },
      "source": [
        "# Feature1: Fasting Glucose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DunEZVnBP1r8"
      },
      "source": [
        "data['Glucose_Output'] = data['glucose'].apply(lambda x: 'diabetes' if x > 125 else 'prediabetes' if x > 99 and x <= 125 else 'normal' if x > 70 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['Glucose_Output'] = data['Glucose_Output'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature1.csv',index=False, header=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWLp9ilEVLDh",
        "outputId": "c0488aaf-ae17-488b-d0c5-1896cf0ffb05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "data1 = pd.read_csv('feature1.csv')\n",
        "data1.head()\n",
        "data1 = data1[['glucose','Glucose_Output']]\n",
        "data1.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>glucose</th>\n",
              "      <th>Glucose_Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>87.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   glucose  Glucose_Output\n",
              "0     82.0               0\n",
              "1     81.0               0\n",
              "2     87.0               0\n",
              "3     91.0               0\n",
              "4     89.0               0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5k6WXh9X5tw",
        "outputId": "ad68d9c6-4b0d-43b8-f9b9-ab1215016781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "data1.to_csv('Feature1.csv', index=False)\n",
        "data1\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>glucose</th>\n",
              "      <th>Glucose_Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>81.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>87.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>126.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>91.927995</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>101.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>103.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>93.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         glucose  Glucose_Output\n",
              "0      82.000000               0\n",
              "1      81.000000               0\n",
              "2      87.000000               0\n",
              "3      91.000000               0\n",
              "4      89.000000               0\n",
              "...          ...             ...\n",
              "5201  126.000000               1\n",
              "5202   91.927995               0\n",
              "5203  101.000000               2\n",
              "5204  103.000000               2\n",
              "5205   93.000000               0\n",
              "\n",
              "[5206 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwQn_tebY71m",
        "outputId": "d5c8a9b6-c08b-4a8d-90f9-e3fab9bfda22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "x1 = data1.iloc[:, 0:1].values\n",
        "y1 = data1.iloc[:, 1].values\n",
        "y1\n",
        "x1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 82.],\n",
              "       [ 81.],\n",
              "       [ 87.],\n",
              "       ...,\n",
              "       [101.],\n",
              "       [103.],\n",
              "       [ 93.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX_-ArVXeuNg",
        "outputId": "5c78000e-e115-4d0f-c664-9aba3726f62a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x1.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5206, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOmhbtjwYI-w"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-gHaELsYRAF",
        "outputId": "f03023af-f067-42b1-a120-5b725d2cf8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "splitRatio = 0.01\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x1,y1,test_size = splitRatio)\n",
        "x_train"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[116.],\n",
              "       [108.],\n",
              "       [ 87.],\n",
              "       ...,\n",
              "       [ 90.],\n",
              "       [ 90.],\n",
              "       [121.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKto4i_SYVJY"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp_cOVQBYYKE",
        "outputId": "e1552d05-5aa9-4297-ed39-e69f602ec5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model =  LogisticRegression()\n",
        "model.fit(x1,y1)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J2r00NHZa55",
        "outputId": "3437ffd3-d87b-4ee5-feb5-ce2b3719eada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "prediction = model.predict_proba(x1)\n",
        "prediction"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.95963746, 0.0030454 , 0.03731714],\n",
              "       [0.9660719 , 0.00245571, 0.03147239],\n",
              "       [0.90591345, 0.00871909, 0.08536746],\n",
              "       ...,\n",
              "       [0.42763043, 0.09196545, 0.48040412],\n",
              "       [0.34061616, 0.11417215, 0.54521169],\n",
              "       [0.76393027, 0.02783906, 0.20823068]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6RPOJ0oHYv",
        "outputId": "846364a7-1eed-444e-bd1c-c157c0d1e4a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmWBshIAanJw"
      },
      "source": [
        "#predictionGlucose = prediction.astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_UrjHKlatzO"
      },
      "source": [
        "outGlucose=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "outGlucose.to_csv('glucosePredictions.csv',index=False, header=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnus0UzLb9tB",
        "outputId": "af5209ab-96b0-4cdd-b6d5-f1848d5af6d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "gluout = pd.read_csv('glucosePredictions.csv')\n",
        "gluout\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.959637</td>\n",
              "      <td>0.003045</td>\n",
              "      <td>0.037317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.966072</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>0.031472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.905913</td>\n",
              "      <td>0.008719</td>\n",
              "      <td>0.085367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.823257</td>\n",
              "      <td>0.019249</td>\n",
              "      <td>0.157494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.870119</td>\n",
              "      <td>0.013053</td>\n",
              "      <td>0.116828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0.006664</td>\n",
              "      <td>0.367731</td>\n",
              "      <td>0.625604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0.797328</td>\n",
              "      <td>0.022905</td>\n",
              "      <td>0.179767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0.427630</td>\n",
              "      <td>0.091965</td>\n",
              "      <td>0.480404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>0.340616</td>\n",
              "      <td>0.114172</td>\n",
              "      <td>0.545212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>0.763930</td>\n",
              "      <td>0.027839</td>\n",
              "      <td>0.208231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2\n",
              "0     0.959637  0.003045  0.037317\n",
              "1     0.966072  0.002456  0.031472\n",
              "2     0.905913  0.008719  0.085367\n",
              "3     0.823257  0.019249  0.157494\n",
              "4     0.870119  0.013053  0.116828\n",
              "...        ...       ...       ...\n",
              "5201  0.006664  0.367731  0.625604\n",
              "5202  0.797328  0.022905  0.179767\n",
              "5203  0.427630  0.091965  0.480404\n",
              "5204  0.340616  0.114172  0.545212\n",
              "5205  0.763930  0.027839  0.208231\n",
              "\n",
              "[5206 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igg9l8LHdfK6"
      },
      "source": [
        "# Feature 2: Age"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tP3BRJYeHRe"
      },
      "source": [
        "Age: prediabetes = (60)34-85, Diabetes= (64)24-84yrs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEqVAbdUcP2e"
      },
      "source": [
        "data['AgeOutput'] = data['age'].apply(lambda x: 'diabetes' if 45 <= x  else 'prediabetes' if x >= 25 and x <= 44 else 'normal' if x < 25 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['AgeOutput'] = data['AgeOutput'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature2.csv',index=False, header=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGWhGbmKjcqX",
        "outputId": "8c163482-1cca-4e44-c159-794658678ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "dataread = pd.read_csv('feature2.csv')\n",
        "dataread\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>glucose</th>\n",
              "      <th>trigs</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>Glucose_Output</th>\n",
              "      <th>AgeOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>11.77</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.700000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>60.00000</td>\n",
              "      <td>2.37</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.300000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>72.00000</td>\n",
              "      <td>3.73</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>94.160745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>3.74</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.600000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>3.13</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.900000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>11.43</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.200000</td>\n",
              "      <td>140.666578</td>\n",
              "      <td>76.05274</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>207.939424</td>\n",
              "      <td>91.927995</td>\n",
              "      <td>205.687652</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>39.2</td>\n",
              "      <td>128.090281</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>33.20</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>6.3</td>\n",
              "      <td>106.720790</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.500000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>74.00000</td>\n",
              "      <td>3.92</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.700000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>78.00000</td>\n",
              "      <td>4.16</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>5.7</td>\n",
              "      <td>96.866305</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age   bmi  ...  Diabetes   Glucose_Output  AgeOutput\n",
              "0          1   21  18.2  ...        0.0               0          0\n",
              "1          0   21  25.9  ...        0.0               0          0\n",
              "2          0   21  29.5  ...        0.0               0          0\n",
              "3          0   21  17.9  ...        0.0               0          0\n",
              "4          0   21  30.6  ...        0.0               0          0\n",
              "...      ...  ...   ...  ...        ...             ...        ...\n",
              "5201       0   77  32.8  ...        1.0               1          1\n",
              "5202       0   77  32.9  ...        0.0               0          1\n",
              "5203       0   77  39.2  ...        1.0               2          1\n",
              "5204       1   77  36.5  ...        0.0               2          1\n",
              "5205       1   77  34.8  ...        1.0               0          1\n",
              "\n",
              "[5206 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY95ocu9kHCp",
        "outputId": "9c7914cc-d512-46b6-c5bb-930ebfd15e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "data2 = pd.read_csv('feature2.csv')\n",
        "data2.head()\n",
        "data2 = data2[['age','AgeOutput']]\n",
        "data2.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>AgeOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  AgeOutput\n",
              "0   21          0\n",
              "1   21          0\n",
              "2   21          0\n",
              "3   21          0\n",
              "4   21          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bp4x5vSkUrQ",
        "outputId": "04ad2d4f-d1ec-4982-c721-6fb03f18b222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "data2.to_csv('Feature2.csv', index=False)\n",
        "data2\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>AgeOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  AgeOutput\n",
              "0      21          0\n",
              "1      21          0\n",
              "2      21          0\n",
              "3      21          0\n",
              "4      21          0\n",
              "...   ...        ...\n",
              "5201   77          1\n",
              "5202   77          1\n",
              "5203   77          1\n",
              "5204   77          1\n",
              "5205   77          1\n",
              "\n",
              "[5206 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo_v9LPkkl14",
        "outputId": "83fc0939-f16d-4ed4-ab8a-fd8d97ef042d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x2 = data2.iloc[:, 0:1].values\n",
        "y2 = data2.iloc[:, 1].values\n",
        "y2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7OsEtSNmFWo",
        "outputId": "9267e600-9cea-4b3a-b729-d433cd620f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model =  LogisticRegression()\n",
        "model.fit(x2,y2)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hypWkLYMmFcO"
      },
      "source": [
        "prediction = model.predict_proba(x2)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d-bTuOEmFQM"
      },
      "source": [
        "outAge=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "outAge.to_csv('AgePredictions.csv',index=False, header=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYL7eXZLJXrd"
      },
      "source": [
        "Try RANDOM FOREST also"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5vaJopZBJuM"
      },
      "source": [
        "# feature 3: BMI "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta_zrioiCBUy"
      },
      "source": [
        "data = pd.read_csv(r'miceDataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tdVUV1-BN2d"
      },
      "source": [
        "data['BMI_Output'] = data['bmi'].apply(lambda x: 'diabetes' if x >= 30 else 'prediabetes' if x > 24 and x < 30 else 'normal' if x < 25 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['BMI_Output'] = data['BMI_Output'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature3.csv',index=False, header=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyaP7ZwkBN0V",
        "outputId": "60cd313e-fe14-497d-c587-5fb705c7693a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "data3 = pd.read_csv('feature3.csv')\n",
        "\n",
        "data3 = data3[['bmi','BMI_Output']]\n",
        "data3.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bmi</th>\n",
              "      <th>BMI_Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    bmi  BMI_Output\n",
              "0  18.2           0\n",
              "1  25.9           2\n",
              "2  29.5           2\n",
              "3  17.9           0\n",
              "4  30.6           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr9Cld5CBNyg",
        "outputId": "a5b7a071-17ac-41d0-a5b1-9082158ea5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "x3 = data1.iloc[:, 0:1].values\n",
        "y3 = data1.iloc[:, 1].values\n",
        "y3\n",
        "x3"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 82.],\n",
              "       [ 81.],\n",
              "       [ 87.],\n",
              "       ...,\n",
              "       [101.],\n",
              "       [103.],\n",
              "       [ 93.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM-2nnO0BNvn",
        "outputId": "cd664e0d-ea66-433d-c918-598526d61221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model =  LogisticRegression()\n",
        "model.fit(x3,y3)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUvIM380BNtE"
      },
      "source": [
        "prediction = model.predict_proba(x3)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40eaD9Y7BNqS"
      },
      "source": [
        "outbmi=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "outbmi.to_csv('BMIPredictions.csv',index=False, header=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciHzVK5EMgWN"
      },
      "source": [
        "# Feature 4: Sys_BP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-8PFV4pMxBN"
      },
      "source": [
        "sys_bp:normal=<124,pre=124-138, diabetes >139"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMqs_snmMus_"
      },
      "source": [
        "data['SysOutput'] = data['sys_bp'].apply(lambda x: 'diabetes' if x > 138 else 'prediabetes' if x > 123 and x <= 138 else 'normal' if x <124 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['SysOutput'] = data['SysOutput'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature4.csv',index=False, header=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REbrJVzgMu3y",
        "outputId": "631a8f65-b8a7-4952-fb1c-d80a174343ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "data4 = pd.read_csv('feature4.csv')\n",
        "data4.head()\n",
        "data4 = data4[['sys_bp','SysOutput']]\n",
        "data4.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>SysOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>114.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>108.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sys_bp  SysOutput\n",
              "0    96.0          0\n",
              "1   110.0          0\n",
              "2   114.0          0\n",
              "3   108.0          0\n",
              "4   134.0          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKh05qp4Mu1X",
        "outputId": "a4e50e27-e50d-4d11-e51d-4931eff09811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "data4.to_csv('Feature4.csv', index=False)\n",
        "data4\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>SysOutput</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>114.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>108.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>130.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>140.666578</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>136.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>128.000000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          sys_bp  SysOutput\n",
              "0      96.000000          0\n",
              "1     110.000000          0\n",
              "2     114.000000          0\n",
              "3     108.000000          0\n",
              "4     134.000000          2\n",
              "...          ...        ...\n",
              "5201  130.000000          2\n",
              "5202  140.666578          1\n",
              "5203  136.000000          2\n",
              "5204  128.000000          2\n",
              "5205  150.000000          1\n",
              "\n",
              "[5206 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oXu-pPGMupr",
        "outputId": "f3fe3491-5580-4058-e3aa-2156e4794434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "x4 = data4.iloc[:, 0:1].values\n",
        "y4 = data4.iloc[:, 1].values\n",
        "y4\n",
        "x4"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 96.],\n",
              "       [110.],\n",
              "       [114.],\n",
              "       ...,\n",
              "       [136.],\n",
              "       [128.],\n",
              "       [150.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcR-WAL3Munb",
        "outputId": "fd427522-25f7-4187-dcd4-3fdc3d0cca93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "model =  LogisticRegression()\n",
        "model.fit(x4,y4)\n",
        "prediction = model.predict_proba(x4)\n",
        "prediction\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00000000e+000, 2.12373863e-128, 3.64579538e-058],\n",
              "       [1.00000000e+000, 1.23539583e-075, 2.19943562e-028],\n",
              "       [1.00000000e+000, 1.47040221e-060, 7.09628349e-020],\n",
              "       ...,\n",
              "       [2.24387606e-028, 2.71894305e-005, 9.99972811e-001],\n",
              "       [2.33587759e-011, 1.99798071e-018, 1.00000000e+000],\n",
              "       [1.41871019e-076, 1.00000000e+000, 3.81418698e-019]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKrSPNJUMulF"
      },
      "source": [
        "outsysbp=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "outsysbp.to_csv('sysBPPredictions.csv',index=False, header=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiwDHTpfQXXC"
      },
      "source": [
        "# Feature 5: Diastolic BP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUs1KNpVRBOE"
      },
      "source": [
        "dia_bp:normal =74 ± 1, 77 ± 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym6EIpMMUJ6A",
        "outputId": "c57f4b59-973d-4f0a-9526-9c217eeb4b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = pd.read_csv(r'miceDataset.csv')\n",
        "x = data.iloc[:, 0:12].values\n",
        "y = data.iloc[:, 12].values\n",
        "x\n",
        "y\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kriz_yErMuin"
      },
      "source": [
        "data['diasOut'] = data['dia_bp'].apply(lambda x: 'diabetes' if x>81 else 'prediabetes' if x <81 and x >75 else 'normal' if x <= 75 else 'diabetes')\n",
        "data.head()\n",
        "  \n",
        "#normal=0, prediabetes=2, diabetes=1\n",
        "data['diasOut'] = data['diasOut'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "data.head()\n",
        "data.to_csv('feature5.csv',index=False, header=True)\n",
        "data5 = pd.read_csv('feature5.csv')\n",
        "data5 = data5[['dia_bp','diasOut']]\n",
        "data5.head()\n",
        "data5.to_csv('Feature5.csv', index=False)\n",
        "data5\n",
        "x5 = data5.iloc[:, 0:1].values\n",
        "y5 = data5.iloc[:, 1].values\n",
        "y5\n",
        "model =  LogisticRegression()\n",
        "model.fit(x5,y5)\n",
        "prediction = model.predict_proba(x5)\n",
        "dias=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "dias.to_csv('diasBPPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8Xd2OEuTTC5"
      },
      "source": [
        "# Feature 6: alb_cr_ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91rBbZq7VWNn"
      },
      "source": [
        "pre=9.6 (2.3–730.7),dia =\t15.8 (2.4–1,242.7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP4XlroITi1c"
      },
      "source": [
        "data['albOut'] = data['alb_cr_ratio'].apply(lambda x: 'diabetes' if  x>30  else 'prediabetes' if x >=3 and x <30 else 'normal' if x <3 else 'diabetes')  \n",
        "\n",
        "data['albOut'] = data['albOut'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature6.csv',index=False, header=True)\n",
        "\n",
        "data6 = pd.read_csv('feature6.csv')\n",
        "data6 = data6[['alb_cr_ratio','albOut']]\n",
        "data6.to_csv('Feature6.csv', index=False)\n",
        "\n",
        "x6 = data6.iloc[:, 0:1].values\n",
        "y6 = data6.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x6,y6)\n",
        "prediction = model.predict_proba(x6)\n",
        "alb=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "alb.to_csv('albcrPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b1eQawPVixq"
      },
      "source": [
        "# Feature 7: WAIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOCsnCvTdezb"
      },
      "source": [
        "normal =89 ± 5, pre=\t99 ± 2,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqR-ItbrWp1Q"
      },
      "source": [
        "data['waist'] = data['waist_cm'].apply(lambda x: 'diabetes' if 101 < x  else 'prediabetes' if x >94 and x <=101 else 'normal' if x <=94 else 'diabetes')  \n",
        "\n",
        "data['waist'] = data['waist'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature7.csv',index=False, header=True)\n",
        "\n",
        "data7 = pd.read_csv('feature7.csv')\n",
        "data7 = data7[['waist_cm','waist']]\n",
        "data7.to_csv('Feature7.csv', index=False)\n",
        "\n",
        "x7 = data7.iloc[:, 0:1].values\n",
        "y7 = data7.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x7,y7)\n",
        "prediction = model.predict_proba(x7)\n",
        "wai=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "wai.to_csv('waistPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MOMgbGZWtmU"
      },
      "source": [
        "# Feature 8:A1C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TszUvYSeMqV"
      },
      "source": [
        "A1C:normal= 4-5.6, pre=(5.7) 4.5–8.0, dia=(7)4.5–8.0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMioyIJwXMwu"
      },
      "source": [
        "data['haemo'] = data['a1c'].apply(lambda x: 'diabetes' if  x>=6.5  else 'prediabetes' if x >=5.7 and x <6.5 else 'normal' if x<5.7 else 'diabetes')  \n",
        "\n",
        "data['haemo'] = data['haemo'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature8.csv',index=False, header=True)\n",
        "\n",
        "data8 = pd.read_csv('feature8.csv')\n",
        "data8 = data8[['a1c','haemo']]\n",
        "data8.to_csv('Feature8.csv', index=False)\n",
        "\n",
        "x8 = data8.iloc[:, 0:1].values\n",
        "y8 = data8.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x8,y8)\n",
        "prediction = model.predict_proba(x8)\n",
        "hg=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "hg.to_csv('a1cPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x2J67bZWyT8"
      },
      "source": [
        "# Feature 9: Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJG0hP10XNym"
      },
      "source": [
        "data['gen'] = data['gender'].apply(lambda x: 'diabetes' if 81 <= x  else 'prediabetes' if x >=81 and x <75 else 'normal' if x <= 75 else 'diabetes')  \n",
        "\n",
        "data['gen'] = data['gen'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature9.csv',index=False, header=True)\n",
        "\n",
        "data9 = pd.read_csv('feature9.csv')\n",
        "data9 = data9[['gender','gen']]\n",
        "data9.to_csv('Feature9.csv', index=False)\n",
        "\n",
        "x9 = data9.iloc[:, 0:1].values\n",
        "y9 = data9.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x9,y9)\n",
        "prediction = model.predict_proba(x9)\n",
        "g=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "g.to_csv('genderPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjuapIIAW3SU"
      },
      "source": [
        "#Feature 10: Trigs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW-3zl3jfHJM"
      },
      "source": [
        "Normal = 0.1-0.7, Pre=(1.3) 0.5-5.3, Diabetes =(1.5) 0.4-7.7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL4NyeiNXO19"
      },
      "source": [
        "data['Tri'] = data['trigs'].apply(lambda x: 'diabetes' if 200<= x  else 'prediabetes' if x >=150 and x <200 else 'normal' if x <150 else 'diabetes')  \n",
        "\n",
        "data['Tri'] = data['Tri'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature10.csv',index=False, header=True)\n",
        "\n",
        "data10 = pd.read_csv('feature10.csv')\n",
        "data10 = data10[['trigs','Tri']]\n",
        "data10.to_csv('Feature10.csv', index=False)\n",
        "\n",
        "x10 = data10.iloc[:, 0:1].values\n",
        "y10 = data10.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x10,y10)\n",
        "prediction = model.predict_proba(x10)\n",
        "gly=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "gly.to_csv('triglyPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRDKorWNW790"
      },
      "source": [
        "# Feature 11: t_chol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CPX1DPsgEHc"
      },
      "source": [
        "t_chol:Normal = 2.6–5.2,pre=(5.4) 2.9–8.9, (4.6)2.5–7.5\t\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAps5gPhXPz_"
      },
      "source": [
        "data['chol'] = data['t_chol'].apply(lambda x: 'diabetes' if 240 <= x  else 'prediabetes' if x >=200 and x <240 else 'normal' if x <200 else 'diabetes')  \n",
        "\n",
        "data['chol'] = data['chol'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature11.csv',index=False, header=True)\n",
        "\n",
        "data11 = pd.read_csv('feature11.csv')\n",
        "data11 = data11[['t_chol','chol']]\n",
        "data11.to_csv('Feature11.csv', index=False)\n",
        "\n",
        "x11 = data11.iloc[:, 0:1].values\n",
        "y11 = data11.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x11,y11)\n",
        "prediction = model.predict_proba(x11)\n",
        "choles=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "choles.to_csv('CholesPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eRzB19vXAMu"
      },
      "source": [
        "# Feature 12: Serum Glucose\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYeUTIYrXQ3b"
      },
      "source": [
        "data['serum'] = data['glucose.1'].apply(lambda x: 'diabetes' if 200 <= x  else 'prediabetes' if x >=140 and x <200 else 'normal' if x<140 else 'diabetes')  \n",
        "\n",
        "data['serum'] = data['serum'].replace(['normal','prediabetes', 'diabetes'],[0,2,1])\n",
        "\n",
        "data.to_csv('feature12.csv',index=False, header=True)\n",
        "\n",
        "data12 = pd.read_csv('feature12.csv')\n",
        "data12 = data12[['glucose.1','serum']]\n",
        "data12.to_csv('Feature12.csv', index=False)\n",
        "\n",
        "x12 = data12.iloc[:, 0:1].values\n",
        "y12 = data12.iloc[:, 1].values\n",
        "\n",
        "model =  LogisticRegression()\n",
        "model.fit(x12,y12)\n",
        "prediction = model.predict_proba(x12)\n",
        "ser=pd.DataFrame(prediction, columns=['0','1','2'])\n",
        "ser.to_csv('SerumGluPredictions.csv',index=False, header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij0eXVcEuTwQ"
      },
      "source": [
        "# Determination of weights by Tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLTgH3Tlv-L_"
      },
      "source": [
        "feature weights\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjLdfPb-vUiy"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vflFvUGWvUu8"
      },
      "source": [
        "transformer = TfidfTransformer(smooth_idf=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrL6G96WvUy2"
      },
      "source": [
        "tfidf = transformer.fit_transform(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPelE8jgvUtF",
        "outputId": "e3853e6c-bb6f-45fd-d3c5-88a27bee5957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "tfidf.toarray()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00744823, 0.09326155, 0.08082667, ..., 0.2398154 , 0.02220513,\n",
              "        0.39081029],\n",
              "       [0.        , 0.07596254, 0.09368713, ..., 0.30023288, 0.01880977,\n",
              "        0.3183192 ],\n",
              "       [0.        , 0.05607968, 0.0787786 , ..., 0.683638  , 0.01361935,\n",
              "        0.25145259],\n",
              "       ...,\n",
              "       [0.        , 0.2085349 , 0.10616322, ..., 0.45769349, 0.01706195,\n",
              "        0.2890261 ],\n",
              "       [0.00525231, 0.24114128, 0.11430723, ..., 0.20982423, 0.01941657,\n",
              "        0.3225656 ],\n",
              "       [0.00468357, 0.21502954, 0.09718218, ..., 0.3267332 , 0.01591777,\n",
              "        0.27050802]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LgdZIYfw35v"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVFOIjNRw1pR"
      },
      "source": [
        "data = pd.read_csv(r'miceDataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibGiRfGjxaLs",
        "outputId": "19c12640-c53b-49dc-9282-68e4785e0b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = data.iloc[:, 0:12].values\n",
        "y = data.iloc[:, 12].values\n",
        "x\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6PjdnGLxcET"
      },
      "source": [
        "ynew=[]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtFC3qczxhET",
        "outputId": "4875aec9-e339-4d41-c5f7-5f22db440920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    ynew.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    ynew.append(add)\n",
        "\n",
        "ynew\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN_GgzzMx10U"
      },
      "source": [
        "from matplotlib import pyplot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qePm5PmQw82d",
        "outputId": "a9317453-0de9-42a4-fa28-d5a5d2dbf658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model = LinearRegression()\n",
        "# fit the model\n",
        "model.fit(x, ynew)\n",
        "# get importance\n",
        "importance = model.coef_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "pyplot.bar([j for j in range(len(importance))], importance)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-e8126266f474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mynew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# get importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hurEpxnZw8yF"
      },
      "source": [
        "label=['gender',\t'age',\t'bmi',\t'waist_cm',\t'sys_bp',\t'dia_bp',\t'alb_cr_ratio',\t\t't_chol',\t\t'glucose',\t'trigs',\t'a1c',\t'glucose.1'\t]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPHZijUVyiM-",
        "outputId": "96f31a1a-ad90-4517-b417-f484880db287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n",
        "# Preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RFclassifier = RandomForestClassifier(n_estimators = 100,random_state=0,warm_start=True)\n",
        "RFclassifier.fit(x_train, y_train)\n",
        "y_pred = RFclassifier.predict(x_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       890\n",
            "           1       0.98      0.83      0.90       152\n",
            "\n",
            "    accuracy                           0.97      1042\n",
            "   macro avg       0.98      0.91      0.94      1042\n",
            "weighted avg       0.97      0.97      0.97      1042\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpyWqitp4A-T"
      },
      "source": [
        "\n",
        "import pickle\n",
        "filename = 'RF.pkl'\n",
        "pickle.dump(RFclassifier, open(filename, 'wb'))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR9hL9m8w8wg",
        "outputId": "fe63c449-7c13-4816-8c85-f487a76b2e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "source": [
        "def plot_feature_importance(importance,names,model_type):\n",
        "  feature_importance = np.array(importance)\n",
        "  feature_names = np.array(names)\n",
        " \n",
        "#Create a DataFrame using a Dictionary\n",
        "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
        "  fi_df = pd.DataFrame(data)\n",
        " \n",
        "#Sort the DataFrame in order decreasing feature importance\n",
        "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
        "  #Define size of bar plot\n",
        "  plt.figure(figsize=(10,8))\n",
        "#Plot Searborn bar chart\n",
        "  sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
        "#Add chart labels\n",
        "  plt.title(model_type + ' FEATURE IMPORTANCE')\n",
        "  plt.xlabel('FEATURE IMPORTANCE')\n",
        "  plt.ylabel('FEATURE NAMES')\n",
        "\n",
        "plot_feature_importance(RFclassifier.feature_importances_,label,'RANDOM FOREST')\n",
        "weight =RFclassifier.feature_importances_\n",
        "print(weight)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00365633 0.02902217 0.02332266 0.0296501  0.01910226 0.01728745\n",
            " 0.03861019 0.03503546 0.11899805 0.02080656 0.49919114 0.16531763]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CH8VCNN8C_z",
        "outputId": "b5432076-9757-450e-f94a-013a8a652165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weight[8]\n",
        "weight[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.027423867439744707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC50Oh3p1b-i"
      },
      "source": [
        "# Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5M9unKu1fWl",
        "outputId": "0c032462-4140-43ed-d448-10f0274b5610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "glucose = pd.read_csv('glucosePredictions.csv')\n",
        "glucose\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.959637</td>\n",
              "      <td>0.003045</td>\n",
              "      <td>0.037317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.966072</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>0.031472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.905913</td>\n",
              "      <td>0.008719</td>\n",
              "      <td>0.085367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.823257</td>\n",
              "      <td>0.019249</td>\n",
              "      <td>0.157494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.870119</td>\n",
              "      <td>0.013053</td>\n",
              "      <td>0.116828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0.006664</td>\n",
              "      <td>0.367731</td>\n",
              "      <td>0.625604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0.797328</td>\n",
              "      <td>0.022905</td>\n",
              "      <td>0.179767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0.427630</td>\n",
              "      <td>0.091965</td>\n",
              "      <td>0.480404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>0.340616</td>\n",
              "      <td>0.114172</td>\n",
              "      <td>0.545212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>0.763930</td>\n",
              "      <td>0.027839</td>\n",
              "      <td>0.208231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2\n",
              "0     0.959637  0.003045  0.037317\n",
              "1     0.966072  0.002456  0.031472\n",
              "2     0.905913  0.008719  0.085367\n",
              "3     0.823257  0.019249  0.157494\n",
              "4     0.870119  0.013053  0.116828\n",
              "...        ...       ...       ...\n",
              "5201  0.006664  0.367731  0.625604\n",
              "5202  0.797328  0.022905  0.179767\n",
              "5203  0.427630  0.091965  0.480404\n",
              "5204  0.340616  0.114172  0.545212\n",
              "5205  0.763930  0.027839  0.208231\n",
              "\n",
              "[5206 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En0X8sIy2mQu"
      },
      "source": [
        "G0=glucose.iloc[:,0]\n",
        "G1=glucose.iloc[:,1]\n",
        "G2=glucose.iloc[:,2]\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYR0ovpd1fTt",
        "outputId": "a29e9a47-e160-4f41-e18e-1e997f30f801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "Age = pd.read_csv('AgePredictions.csv')\n",
        "Age\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>5.299464e-63</td>\n",
              "      <td>1.930293e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>6.213459e-205</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.776281e-75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0             1             2\n",
              "0      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "1      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "2      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "3      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "4      1.000000e+00  5.299464e-63  1.930293e-09\n",
              "...             ...           ...           ...\n",
              "5201  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "5202  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "5203  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "5204  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "5205  6.213459e-205  1.000000e+00  7.776281e-75\n",
              "\n",
              "[5206 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6jJ3YKI1fSK"
      },
      "source": [
        "A0=Age.iloc[:,0]\n",
        "A1=Age.iloc[:,1]\n",
        "A2=Age.iloc[:,2]\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnRA_0pYj2iJ"
      },
      "source": [
        "bmi = pd.read_csv('BMIPredictions.csv')\n",
        "bmi\n",
        "\n",
        "B0=bmi.iloc[:,0]\n",
        "B1=bmi.iloc[:,1]\n",
        "B2=bmi.iloc[:,2]\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OvrGTlOmNak"
      },
      "source": [
        "wai = pd.read_csv('waistPredictions.csv')\n",
        "wai\n",
        "\n",
        "W0=wai.iloc[:,0]\n",
        "W1=wai.iloc[:,1]\n",
        "W2=wai.iloc[:,2]\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WK58shcmZnX"
      },
      "source": [
        "sys = pd.read_csv('sysBPPredictions.csv')\n",
        "sys\n",
        "\n",
        "S0=sys.iloc[:,0]\n",
        "S1=sys.iloc[:,1]\n",
        "S2=sys.iloc[:,2]\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCnCZF_jmjM5"
      },
      "source": [
        "dia = pd.read_csv('diasBPPredictions.csv')\n",
        "dia\n",
        "\n",
        "D0=dia.iloc[:,0]\n",
        "D1=dia.iloc[:,1]\n",
        "D2=dia.iloc[:,2]\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7eq6qyymtHi"
      },
      "source": [
        "ratio = pd.read_csv('albcrPredictions.csv')\n",
        "ratio\n",
        "\n",
        "alb0=ratio.iloc[:,0]\n",
        "alb1=ratio.iloc[:,1]\n",
        "alb2=ratio.iloc[:,2]\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhvv0f9rm6k1"
      },
      "source": [
        "chol = pd.read_csv('CholesPredictions.csv')\n",
        "chol\n",
        "\n",
        "C0=chol.iloc[:,0]\n",
        "C1=chol.iloc[:,1]\n",
        "C2=chol.iloc[:,2]\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ft7PFq6nFNK"
      },
      "source": [
        "tr = pd.read_csv('triglyPredictions.csv')\n",
        "tr\n",
        "\n",
        "T0=tr.iloc[:,0]\n",
        "T1=tr.iloc[:,1]\n",
        "T2=tr.iloc[:,2]\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCZDK2hhnUNj"
      },
      "source": [
        "a1c = pd.read_csv('a1cPredictions.csv')\n",
        "a1c\n",
        "\n",
        "a1c0=a1c.iloc[:,0]\n",
        "a1c1=a1c.iloc[:,1]\n",
        "a1c2=a1c.iloc[:,2]\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd8hMcFfngr-"
      },
      "source": [
        "pl = pd.read_csv('SerumGluPredictions.csv')\n",
        "pl\n",
        "\n",
        "Se0=pl.iloc[:,0]\n",
        "Se1=pl.iloc[:,1]\n",
        "Se2=pl.iloc[:,2]\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5efICtcn4eK"
      },
      "source": [
        "pl = pd.read_csv('SerumGluPredictions.csv')\n",
        "pl\n",
        "\n",
        "Se0=pl.iloc[:,0]\n",
        "Se1=pl.iloc[:,1]\n",
        "Se2=pl.iloc[:,2]\n",
        "####Gender ---take the same output as existing"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqyGr7CiyTzf"
      },
      "source": [
        "\n",
        "Gen0=B0\n",
        "Gen1=B1\n",
        "Gen2=B2\n",
        "####Gender ---take the same output as existing"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5-aSPt-4nyl"
      },
      "source": [
        "G0,G1,G2 for Glucose\n",
        "A0,A1,A2 for Age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYiOQdz44vwx"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Ufejzy6AqL",
        "outputId": "0be602b7-bcaa-4dff-f924-629b62cc4f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sum0=[]\n",
        "sum1=[]\n",
        "sum2=[]\n",
        "res=[]\n",
        "for (a0,a1,a2,b0,b1,b2,c0,c1,c2,d0,d1,d2,e0,e1,e2,f0,f1,f2,g0,g1,g2,h0,h1,h2,i0,i1,i2,j0,j1,j2,k0,k1,k2,l0,l1,l2) in zip(Gen0,Gen1,Gen2,A0,A1,A2,B0,B1,B2,W0,W1,W2,S0,S1,S2,D0,D1,D2,alb0,alb1,alb2,C0,C1,C2,G0,G1,G2,T0,T1,T2,a1c0,a1c1,a1c2,Se0,Se1,Se2):\n",
        "\n",
        "  s0= (a0*weight[0])+(b0*weight[1])+(c0*weight[2])+(d0*weight[3])+(e0*weight[4])+(f0*weight[5])+(g0*weight[6])+(h0*weight[7])+(i0*weight[8])+(j0*weight[9])+(k0*weight[10])+(l0*weight[11])\n",
        "  s1= (a1*weight[0])+(b1*weight[1])+(c1*weight[2])+(d1*weight[3])+(e1*weight[4])+(f1*weight[5])+(g1*weight[6])+(h1*weight[7])+(i1*weight[8])+(j1*weight[9])+(k1*weight[10])+(l1*weight[11])\n",
        "  s2= (a2*weight[0])+(b2*weight[1])+(c2*weight[2])+(d2*weight[3])+(e2*weight[4])+(f2*weight[5])+(g2*weight[6])+(h2*weight[7])+(i2*weight[8])+(j2*weight[9])+(k2*weight[10])+(l2*weight[11])\n",
        "\n",
        "  result =max(s0,s1,s2)\n",
        "  if result ==s0:\n",
        "    add=0\n",
        "  elif result ==s1:\n",
        "    add=1\n",
        "  elif result==s2:\n",
        "    add=2\n",
        "\n",
        "  res.append(add)\n",
        "\n",
        "print('result',res)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 2, 1, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 0, 0, 2, 0, 2, 2, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 1, 0, 2, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 1, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 2, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 0, 0, 1, 2, 2, 0, 2, 1, 2, 0, 0, 0, 2, 1, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 1, 0, 2, 2, 2, 1, 2, 2, 0, 2, 0, 0, 2, 1, 2, 0, 2, 2, 1, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 1, 2, 2, 1, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 2, 1, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 0, 2, 0, 1, 1, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 1, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 1, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 0, 2, 2, 0, 0, 0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 0, 0, 0, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 0, 2, 0, 0, 2, 2, 2, 1, 1, 1, 2, 1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 0, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2, 0, 0, 0, 1, 0, 2, 2, 0, 0, 2, 1, 1, 1, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 1, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 2, 1, 1, 2, 0, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 2, 2, 0, 0, 0, 2, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 2, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 1, 0, 2, 0, 2, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 0, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wBJEnZvJAKc"
      },
      "source": [
        "df = pd.DataFrame(res)  \n",
        "\n",
        "df.to_csv('result.csv',index=False, header=True)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doBnB7FRJ6y8",
        "outputId": "7af32987-aa92-41f3-be1c-491889aed267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "df1 = pd.read_csv('miceDataset.csv')\n",
        "df2 = pd.read_csv('result.csv')\n",
        "\n",
        "\n",
        "Merged = pd.concat([df1, df2], axis = 1)\n",
        "Merged"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>glucose</th>\n",
              "      <th>trigs</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>11.77</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.700000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>60.00000</td>\n",
              "      <td>2.37</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.300000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>72.00000</td>\n",
              "      <td>3.73</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>94.160745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>3.74</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.600000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>3.13</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.900000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>11.43</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.200000</td>\n",
              "      <td>140.666578</td>\n",
              "      <td>76.05274</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>207.939424</td>\n",
              "      <td>91.927995</td>\n",
              "      <td>205.687652</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>39.2</td>\n",
              "      <td>128.090281</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>33.20</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>6.3</td>\n",
              "      <td>106.720790</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.500000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>74.00000</td>\n",
              "      <td>3.92</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.700000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>78.00000</td>\n",
              "      <td>4.16</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>5.7</td>\n",
              "      <td>96.866305</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age   bmi    waist_cm  ...  a1c   glucose.1  Diabetes   0\n",
              "0          1   21  18.2   82.000000  ...  5.0   88.000000        0.0  0\n",
              "1          0   21  25.9   93.700000  ...  5.2   88.000000        0.0  0\n",
              "2          0   21  29.5  102.300000  ...  5.1   94.160745        0.0  0\n",
              "3          0   21  17.9   69.100000  ...  5.1   95.000000        0.0  0\n",
              "4          0   21  30.6  101.600000  ...  6.0   95.000000        0.0  2\n",
              "...      ...  ...   ...         ...  ...  ...         ...        ... ..\n",
              "5201       0   77  32.8  115.900000  ...  6.5  134.000000        1.0  2\n",
              "5202       0   77  32.9  122.200000  ...  6.2   98.000000        0.0  2\n",
              "5203       0   77  39.2  128.090281  ...  6.3  106.720790        1.0  2\n",
              "5204       1   77  36.5  119.500000  ...  6.2  103.000000        0.0  2\n",
              "5205       1   77  34.8  104.700000  ...  5.7   96.866305        1.0  2\n",
              "\n",
              "[5206 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCgDvDVULA7a"
      },
      "source": [
        "Merged.to_csv('finalDiabetes.csv',index=False)\n",
        "\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCR2kVw44NJu"
      },
      "source": [
        "df = pd.read_csv('finalDiabetes.csv')\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln3ccyq62-lx"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SACG0CQI23xu"
      },
      "source": [
        "model =  pickle.load(open(\"thresholded993RF.pkl\",\"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIiPunmCqsJV"
      },
      "source": [
        "label=['gender',\t'age',\t'bmi',\t'waist_cm',\t'sys_bp',\t'dia_bp',\t'alb_cr_ratio',\t\t't_chol',\t\t'glucose',\t'trigs',\t'a1c',\t'glucose.1'\t]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4pDz-S8rUTN"
      },
      "source": [
        "new_df = pd.DataFrame([[1,21,18.2,82,96,50,11.77,118,82,54,5,88]])\n",
        "prediction = RFclassifier.predict(new_df)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP00X4k23Vdl",
        "outputId": "e070e81e-ca15-482b-e08d-6bf3cb4a1fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yFJewoB12H-"
      },
      "source": [
        "newy=[]\n",
        "newy=ynew"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5UyGTh33V0T"
      },
      "source": [
        "ones=[]\n",
        "zeros=[]\n",
        "rem=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "big0QOXo4cBb",
        "outputId": "927d19dc-cafc-4f80-9b1e-b38cdd7cb4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(newy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTBMiqyD4whE"
      },
      "source": [
        "len(res)\n",
        "rem=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6KkSya_5y23",
        "outputId": "7036063e-ef34-4c6e-aeb4-9b60c2a55a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(newy)\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n",
            "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 2, 1, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 2, 2, 0, 0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 2, 0, 0, 0, 2, 0, 2, 2, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 1, 0, 2, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 1, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 2, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 1, 2, 2, 0, 2, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 2, 0, 0, 1, 2, 2, 0, 2, 1, 2, 0, 0, 0, 2, 1, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 1, 0, 2, 2, 2, 1, 2, 2, 0, 2, 0, 0, 2, 1, 2, 0, 2, 2, 1, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 0, 2, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 1, 2, 2, 1, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 2, 1, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 2, 2, 0, 1, 1, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 1, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 1, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 1, 0, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 2, 0, 2, 2, 0, 0, 0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 0, 0, 0, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 0, 2, 0, 0, 2, 2, 2, 1, 1, 1, 2, 1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 0, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2, 0, 0, 0, 1, 0, 2, 2, 0, 0, 2, 1, 1, 1, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 1, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 2, 1, 1, 2, 0, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 1, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 2, 0, 2, 0, 2, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 1, 0, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 1, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUp9I-Ts2Obd",
        "outputId": "4f6b377a-78b7-45c3-ec56-ce8726cd0f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "for i,j in zip(newy,res):\n",
        "  if i==j:\n",
        "    if i==1:\n",
        "          add=1\n",
        "          ones.append(add)\n",
        "    elif i==0:\n",
        "                add=0\n",
        "                zeros.append(add)\n",
        "  else:\n",
        "    add=2\n",
        "    rem.append(add)\n",
        "\n",
        "print(len(ones))\n",
        "print(len(zeros))\n",
        "len(rem)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "567\n",
            "3134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1505"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIz4FhFV7KZ_"
      },
      "source": [
        "data = pd.read_csv(r'finalDiabetes.csv')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D6bvkPC4fLn",
        "outputId": "2407a864-3194-4986-dd88-62e6107a472d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>glucose</th>\n",
              "      <th>trigs</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>11.77</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.700000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>60.00000</td>\n",
              "      <td>2.37</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.300000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>72.00000</td>\n",
              "      <td>3.73</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>94.160745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.100000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>3.74</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.600000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>3.13</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.900000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>64.00000</td>\n",
              "      <td>11.43</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.200000</td>\n",
              "      <td>140.666578</td>\n",
              "      <td>76.05274</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>207.939424</td>\n",
              "      <td>91.927995</td>\n",
              "      <td>205.687652</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>39.2</td>\n",
              "      <td>128.090281</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>33.20</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>6.3</td>\n",
              "      <td>106.720790</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.500000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>74.00000</td>\n",
              "      <td>3.92</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.700000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>78.00000</td>\n",
              "      <td>4.16</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>5.7</td>\n",
              "      <td>96.866305</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age   bmi    waist_cm  ...  a1c   glucose.1  Diabetes   0\n",
              "0          1   21  18.2   82.000000  ...  5.0   88.000000        0.0  0\n",
              "1          0   21  25.9   93.700000  ...  5.2   88.000000        0.0  0\n",
              "2          0   21  29.5  102.300000  ...  5.1   94.160745        0.0  0\n",
              "3          0   21  17.9   69.100000  ...  5.1   95.000000        0.0  0\n",
              "4          0   21  30.6  101.600000  ...  6.0   95.000000        0.0  2\n",
              "...      ...  ...   ...         ...  ...  ...         ...        ... ..\n",
              "5201       0   77  32.8  115.900000  ...  6.5  134.000000        1.0  2\n",
              "5202       0   77  32.9  122.200000  ...  6.2   98.000000        0.0  2\n",
              "5203       0   77  39.2  128.090281  ...  6.3  106.720790        1.0  2\n",
              "5204       1   77  36.5  119.500000  ...  6.2  103.000000        0.0  2\n",
              "5205       1   77  34.8  104.700000  ...  5.7   96.866305        1.0  2\n",
              "\n",
              "[5206 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4my9RrD7Ogn",
        "outputId": "d7e4d141-cf1b-4070-b7a4-b21b6b6629d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = data.iloc[:, 0:12].values\n",
        "y = data.iloc[:, 13].values\n",
        "\n",
        "y"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcqf4VKX7SfM"
      },
      "source": [
        "res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pXHH3iE8ZZ0"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSwwPIjG47IQ",
        "outputId": "f76d124a-00c9-4b69-ef74-ad341c6c9a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "RFclassifier = RandomForestClassifier(n_estimators = 200,random_state=0,warm_start=True)\n",
        "RFclassifier.fit(x_train, y_train)\n",
        "y_pred = RFclassifier.predict(x_test)\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "acc=accuracy_score(y_test,y_pred)\n",
        "print(acc)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9836852207293666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5khsx4W162xa",
        "outputId": "9b9e8b51-383c-4e61-fcf2-bc1e4e38c3e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        }
      },
      "source": [
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "# Preprocessing\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "  RFclassifier = RandomForestClassifier(n_estimators = 100,random_state=0,warm_start=True)\n",
        "  RFclassifier.fit(x_train, y_train)\n",
        "  y_pred = RFclassifier.predict(x_test)\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test,y_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5988483685220729\n",
            "0.6103646833013435\n",
            "0.6084452975047985\n",
            "0.6372360844529751\n",
            "0.6401151631477927\n",
            "0.5950095969289827\n",
            "0.6036468330134357\n",
            "0.5863723608445297\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-18a9e73c9385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mRFclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mRFclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m#print(confusion_matrix(y_test, y_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJsGBP8v-tie"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlhWhiiWBzdw",
        "outputId": "a041ed0b-0bb0-4452-c78c-509d44ff2bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 0, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flST5s9D-BUB",
        "outputId": "f19a1bbe-ad77-40c7-84d7-e49224b11043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "print('Classifier Type: Random Forest')\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test, y_pred))\n",
        "acc=accuracy_score(y_test,y_pred)\n",
        "print('Accuracy: ',acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier Type: Random Forest\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       633\n",
            "           1       0.99      0.99      0.99       119\n",
            "           2       0.99      0.98      0.99       290\n",
            "\n",
            "    accuracy                           0.99      1042\n",
            "   macro avg       0.99      0.99      0.99      1042\n",
            "weighted avg       0.99      0.99      0.99      1042\n",
            "\n",
            "Accuracy:  0.9932821497120922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujteOJW7DAEu",
        "outputId": "7b7d3c8d-c402-4933-813c-978ff012adc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('ROC_AUC_SCORE: ',multiclass_roc_auc_score(y_test,y_pred,average='macro'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC_AUC_SCORE:  0.9932087552211982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADpkt0c2CtHd"
      },
      "source": [
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "  lb = LabelBinarizer()\n",
        "  lb.fit(y_test)\n",
        "  y_test = lb.transform(y_test)\n",
        "  y_pred = lb.transform(y_pred)\n",
        "  return roc_auc_score(y_test, y_pred, average=average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuAn5WfMDUWo"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ_ybKmOFdD0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EAcZlV-8T9N"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, res, test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv-wuwT28w6N"
      },
      "source": [
        "\n",
        "import pickle\n",
        "filename = 'done.pkl'\n",
        "pickle.dump(RFclassifier, open(filename, 'wb'))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV9SDeXYFsxm"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmFsHjt26kxO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAGCJfWwFfP0",
        "outputId": "1daf18a9-7404-4618-e355-a14dfc17bd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "# Preprocessing\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "  LRclassifier = LogisticRegression()\n",
        "  LRclassifier.fit(x_train, y_train)\n",
        "  y_pred = LRclassifier.predict(x_test)\n",
        "  acc=accuracy_score(y_test,y_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6046065259117083\n",
            "0.6190019193857965\n",
            "0.5959692898272553\n",
            "0.6305182341650671\n",
            "0.6410748560460653\n",
            "0.6343570057581573\n",
            "0.6142034548944337\n",
            "0.6209213051823417\n",
            "0.6228406909788867\n",
            "0.6362763915547025\n",
            "0.6065259117082533\n",
            "0.6314779270633397\n",
            "0.6439539347408829\n",
            "0.6122840690978887\n",
            "0.6190019193857965\n",
            "0.6266794625719769\n",
            "0.6209213051823417\n",
            "0.6324376199616123\n",
            "0.6362763915547025\n",
            "0.6410748560460653\n",
            "0.6122840690978887\n",
            "0.6458733205374281\n",
            "0.6372360844529751\n",
            "0.6343570057581573\n",
            "0.6247600767754319\n",
            "0.6065259117082533\n",
            "0.6276391554702495\n",
            "0.6209213051823417\n",
            "0.6065259117082533\n",
            "0.6218809980806143\n",
            "0.6180422264875239\n",
            "0.6094049904030711\n",
            "0.6209213051823417\n",
            "0.6065259117082533\n",
            "0.6266794625719769\n",
            "0.6333973128598849\n",
            "0.6084452975047985\n",
            "0.6381957773512476\n",
            "0.6209213051823417\n",
            "0.6324376199616123\n",
            "0.5959692898272553\n",
            "0.6122840690978887\n",
            "0.6266794625719769\n",
            "0.6372360844529751\n",
            "0.6132437619961613\n",
            "0.6266794625719769\n",
            "0.6209213051823417\n",
            "0.6218809980806143\n",
            "0.5950095969289827\n",
            "0.6103646833013435\n",
            "0.6247600767754319\n",
            "0.6266794625719769\n",
            "0.6266794625719769\n",
            "0.6314779270633397\n",
            "0.6372360844529751\n",
            "0.6046065259117083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-6ec95aa6c023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mLRclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mLRclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             )\n\u001b[1;32m    938\u001b[0m             n_iter_i = _check_optimize_result(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_multi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6IiOcXIGC5K",
        "outputId": "2d696b1a-a699-4e60-d2a2-758599775ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print('Classifier Type: Logistic Regression')\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test, y_pred))\n",
        "acc=accuracy_score(y_test,y_pred)\n",
        "print('Accuracy: ',acc)\n",
        "print('ROC_AUC_SCORE: ',multiclass_roc_auc_score(y_test,y_pred,average='macro'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier Type: Logistic Regression\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       637\n",
            "           1       1.00      0.99      1.00       138\n",
            "           2       0.97      0.96      0.96       267\n",
            "\n",
            "    accuracy                           0.98      1042\n",
            "   macro avg       0.98      0.98      0.98      1042\n",
            "weighted avg       0.98      0.98      0.98      1042\n",
            "\n",
            "Accuracy:  0.9817658349328215\n",
            "ROC_AUC_SCORE:  0.9838471726424024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l_fmYeHGuy1"
      },
      "source": [
        "\n",
        "# Polynomial Kernel\n",
        "from sklearn.svm import SVC   # Support Vector Classifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QahHrf93HfjH"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc4954zGGkkT",
        "outputId": "2a677644-0ed9-4f3d-de5c-86d38c600a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "# Preprocessing\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "  SVMclassifier = SVC(kernel='rbf')\n",
        "  SVMclassifier.fit(x_train, y_train) \n",
        "  y_pred = SVMclassifier.predict(x_test)\n",
        "  acc=accuracy_score(y_test,y_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n",
        "\n",
        "print('Classifier Type: SVM')\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test, y_pred))\n",
        "acc=accuracy_score(y_test,y_pred)\n",
        "print('Accuracy: ',acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6314779270633397\n",
            "Classifier Type: SVM\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.92      0.78       641\n",
            "           1       0.47      0.07      0.13       122\n",
            "           2       0.41      0.20      0.27       279\n",
            "\n",
            "    accuracy                           0.63      1042\n",
            "   macro avg       0.52      0.40      0.39      1042\n",
            "weighted avg       0.58      0.63      0.57      1042\n",
            "\n",
            "Accuracy:  0.6314779270633397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Chenm7khob"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6vzGNtydlBy"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POe4-7Hcd5MI"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBcr3-6UVmiL"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPWlfj2dd7_-"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0A6ktnad-jl"
      },
      "source": [
        "RFclassifier = RandomForestClassifier(n_estimators = 100,random_state=0,warm_start=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfgQl7t0eCnx",
        "outputId": "23d03a12-a1bd-471a-a12e-692a23eedf1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "RFclassifier.fit(x_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xwxXkESiDLF"
      },
      "source": [
        "y_pred = RFclassifier.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF7EvAnviILD",
        "outputId": "da107ea6-4802-4af5-ea8d-ca355b65dfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, y_pred)\n",
        "  print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[890   1]\n",
            " [ 27 123]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       891\n",
            "           1       0.99      0.82      0.90       150\n",
            "\n",
            "    accuracy                           0.97      1041\n",
            "   macro avg       0.98      0.91      0.94      1041\n",
            "weighted avg       0.97      0.97      0.97      1041\n",
            "\n",
            "0.9731027857829011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osejj5pViMok"
      },
      "source": [
        "\n",
        "import pickle\n",
        "filename = 'rf1.pkl'\n",
        "pickle.dump(RFclassifier, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syh6A9qliuFR",
        "outputId": "1b3ac81b-ad5c-4ad7-d86b-d937eb6b1c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "pip install sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc9e8zqEixAE"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2rtuOTligJr",
        "outputId": "66e38b37-a185-443b-9702-e9e27b1939b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "roc_auc_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.909438832772166"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0vcrAq2jKY6"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjwo9F7ai5e0"
      },
      "source": [
        "trial 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMgxlZBWi7je"
      },
      "source": [
        "while acc<0.98:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "\n",
        "  RFclassifier = RandomForestClassifier(n_estimators = 200,random_state=0,warm_start=True)\n",
        "  RFclassifier.fit(x_train, y_train)\n",
        "  y_pred = RFclassifier.predict(x_test)\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "  #print(classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, y_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdTdSv64kwQ1",
        "outputId": "62d6099b-4432-4f35-f7b8-7d2c53288b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "  print('confusion matrix',confusion_matrix(y_test, y_pred))\n",
        "  print('Classification report',classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, y_pred)\n",
        "  print('accuracy',acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix [[903   2]\n",
            " [ 17 119]]\n",
            "Classification report               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       905\n",
            "           1       0.98      0.88      0.93       136\n",
            "\n",
            "    accuracy                           0.98      1041\n",
            "   macro avg       0.98      0.94      0.96      1041\n",
            "weighted avg       0.98      0.98      0.98      1041\n",
            "\n",
            "accuracy 0.9817483189241114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC4A003QksF4",
        "outputId": "605c2002-220a-4137-cdf8-66b35113276a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('AUC score',roc_auc_score(y_test,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score 0.9363950276243094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCmSZY5mkVlW"
      },
      "source": [
        "\n",
        "import pickle\n",
        "filename = 'rf2.pkl'\n",
        "pickle.dump(RFclassifier, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoKLVBuCVroy"
      },
      "source": [
        "import pandas as pd\n",
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from fancyimpute import IterativeImputer\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD-9WOmAWGRO"
      },
      "source": [
        "# LGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ewUQGXVxO8"
      },
      "source": [
        "lgb_clf = lgb.LGBMClassifier(random_state=0, silent=True, metric='None', n_jobs=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HerliRemV3Eq",
        "outputId": "a14dfa6e-8eb7-44ea-ec93-544905652af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "lgb_clf.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "               metric='None', min_child_samples=20, min_child_weight=0.001,\n",
              "               min_split_gain=0.0, n_estimators=100, n_jobs=4, num_leaves=31,\n",
              "               objective=None, random_state=0, reg_alpha=0.0, reg_lambda=0.0,\n",
              "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
              "               subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alJ3FJ3aV55I"
      },
      "source": [
        "y_pred = lgb_clf.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ3TWRoul0Dt"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFp5l8UOlk0T"
      },
      "source": [
        "pickle.dump(lgb_clf, open('lgbClassifier.pkl', 'wb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoG_ypbxXdeC",
        "outputId": "5ceb0341-e716-4e27-a522-ceae2e937960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       886\n",
            "           1       0.97      0.81      0.88       155\n",
            "\n",
            "    accuracy                           0.97      1041\n",
            "   macro avg       0.97      0.90      0.93      1041\n",
            "weighted avg       0.97      0.97      0.97      1041\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwmQweampKTg"
      },
      "source": [
        "# BORUTA SELECTOR + RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiDfvaKEn2o8",
        "outputId": "dd382d62-8364-40d1-d00c-3e2672feae3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "pip install boruta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boruta\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/11/583f4eac99d802c79af9217e1eff56027742a69e6c866b295cce6a5a8fc2/Boruta-0.3-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from boruta) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from boruta) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from boruta) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17.1->boruta) (0.16.0)\n",
            "Installing collected packages: boruta\n",
            "Successfully installed boruta-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKVVxGU-Xe_W"
      },
      "source": [
        "from boruta import BorutaPy\n",
        "from datetime import datetime\n",
        "from __future__ import print_function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS8GjTG0snJ8"
      },
      "source": [
        "def timer(start_time=None):\n",
        "    if not start_time:\n",
        "        start_time = datetime.now()\n",
        "        return start_time\n",
        "    elif start_time:\n",
        "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
        "        tmin, tsec = divmod(temp_sec, 60)\n",
        "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4xKVY4YssNm"
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=200, class_weight='balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "327MbkQntJKN",
        "outputId": "98911558-a83f-4609-8d13-67b34bbfea3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2)\n",
        "start_time = timer(None)\n",
        "boruta_selector.fit(x_train, y_train)\n",
        "timer(start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t65\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t12\n",
            "Rejected: \t26\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t9\n",
            "Rejected: \t29\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t9\n",
            "Rejected: \t29\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t9\n",
            "Rejected: \t29\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t6\n",
            "Rejected: \t32\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t6\n",
            "Rejected: \t32\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t6\n",
            "Rejected: \t32\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t4\n",
            "Rejected: \t34\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t3\n",
            "Rejected: \t35\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t2\n",
            "Rejected: \t36\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t27\n",
            "Tentative: \t0\n",
            "Rejected: \t36\n",
            "\n",
            " Time taken: 0 hours 1 minutes and 28.77 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1orVYVvt4j-",
        "outputId": "bd3c5cc6-a407-4ed7-d813-956329c09a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>race</th>\n",
              "      <th>education</th>\n",
              "      <th>marital</th>\n",
              "      <th>income</th>\n",
              "      <th>household_size</th>\n",
              "      <th>insurance</th>\n",
              "      <th>private_insur</th>\n",
              "      <th>gen_health</th>\n",
              "      <th>asthma</th>\n",
              "      <th>chf</th>\n",
              "      <th>cad</th>\n",
              "      <th>mi</th>\n",
              "      <th>cva</th>\n",
              "      <th>copd</th>\n",
              "      <th>cancer</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>depression</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>smoker</th>\n",
              "      <th>drinks_day</th>\n",
              "      <th>weight_kg</th>\n",
              "      <th>height_cm</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>alb</th>\n",
              "      <th>alt</th>\n",
              "      <th>ast</th>\n",
              "      <th>alk_phos</th>\n",
              "      <th>bun</th>\n",
              "      <th>ca</th>\n",
              "      <th>cpk</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>bicarb</th>\n",
              "      <th>cr</th>\n",
              "      <th>glucose</th>\n",
              "      <th>iron</th>\n",
              "      <th>ldh</th>\n",
              "      <th>phos</th>\n",
              "      <th>t_bilirubin</th>\n",
              "      <th>t_protein</th>\n",
              "      <th>u_acid</th>\n",
              "      <th>sodium</th>\n",
              "      <th>potassium</th>\n",
              "      <th>chloride</th>\n",
              "      <th>glob</th>\n",
              "      <th>trigs</th>\n",
              "      <th>wbc</th>\n",
              "      <th>hgb</th>\n",
              "      <th>hct</th>\n",
              "      <th>platelets</th>\n",
              "      <th>s_cotinine</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>insulin</th>\n",
              "      <th>hdl</th>\n",
              "      <th>ldl_chol</th>\n",
              "      <th>grip_strength</th>\n",
              "      <th>fvc</th>\n",
              "      <th>fev1</th>\n",
              "      <th>fev1_fvc_ratio</th>\n",
              "      <th>Diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>50.8</td>\n",
              "      <td>167.1</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>11.77</td>\n",
              "      <td>4.4</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.8</td>\n",
              "      <td>35.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.44</td>\n",
              "      <td>82.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>105.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>54.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.7</td>\n",
              "      <td>36.1</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.654</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>7.27</td>\n",
              "      <td>47.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>50.3</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>2846.0</td>\n",
              "      <td>0.779726</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>72.8</td>\n",
              "      <td>167.5</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.7</td>\n",
              "      <td>110.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2.37</td>\n",
              "      <td>4.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>214.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.81</td>\n",
              "      <td>81.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.2</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.8</td>\n",
              "      <td>137.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>102.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>83.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>15.1</td>\n",
              "      <td>44.4</td>\n",
              "      <td>226.0</td>\n",
              "      <td>0.221</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88.0</td>\n",
              "      <td>12.01</td>\n",
              "      <td>40.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>90.1</td>\n",
              "      <td>4327.0</td>\n",
              "      <td>3629.0</td>\n",
              "      <td>0.838687</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>165.6</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.3</td>\n",
              "      <td>114.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>4.5</td>\n",
              "      <td>23.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.3</td>\n",
              "      <td>73.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.82</td>\n",
              "      <td>87.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>7.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>104.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>8.2</td>\n",
              "      <td>14.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>266.0</td>\n",
              "      <td>0.011</td>\n",
              "      <td>5.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.7</td>\n",
              "      <td>4471.0</td>\n",
              "      <td>3725.0</td>\n",
              "      <td>0.833147</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>56.9</td>\n",
              "      <td>178.3</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.1</td>\n",
              "      <td>108.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>3.74</td>\n",
              "      <td>4.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.5</td>\n",
              "      <td>151.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.73</td>\n",
              "      <td>91.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.9</td>\n",
              "      <td>136.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>102.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>57.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>14.7</td>\n",
              "      <td>43.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>16.300</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95.0</td>\n",
              "      <td>3.60</td>\n",
              "      <td>55.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>86.6</td>\n",
              "      <td>5161.0</td>\n",
              "      <td>4301.0</td>\n",
              "      <td>0.833366</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>101.2</td>\n",
              "      <td>181.9</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.6</td>\n",
              "      <td>134.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>4.3</td>\n",
              "      <td>20.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>250.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.07</td>\n",
              "      <td>89.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7.2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>142.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>104.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>70.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>15.6</td>\n",
              "      <td>45.1</td>\n",
              "      <td>306.0</td>\n",
              "      <td>212.000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>14.58</td>\n",
              "      <td>39.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>94.4</td>\n",
              "      <td>6250.0</td>\n",
              "      <td>5168.0</td>\n",
              "      <td>0.826880</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.6</td>\n",
              "      <td>161.5</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.9</td>\n",
              "      <td>130.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>11.43</td>\n",
              "      <td>4.2</td>\n",
              "      <td>26.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>198.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.73</td>\n",
              "      <td>126.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.6</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>107.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>130.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>41.8</td>\n",
              "      <td>205.0</td>\n",
              "      <td>0.269</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134.0</td>\n",
              "      <td>19.13</td>\n",
              "      <td>45.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>65.2</td>\n",
              "      <td>3097.0</td>\n",
              "      <td>2249.0</td>\n",
              "      <td>0.726187</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>104.6</td>\n",
              "      <td>178.3</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>10.4</td>\n",
              "      <td>29.6</td>\n",
              "      <td>141.0</td>\n",
              "      <td>143.000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2872.0</td>\n",
              "      <td>1716.0</td>\n",
              "      <td>0.597493</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>39.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>33.20</td>\n",
              "      <td>3.6</td>\n",
              "      <td>32.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>94.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.98</td>\n",
              "      <td>101.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.2</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>104.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>169.0</td>\n",
              "      <td>10.7</td>\n",
              "      <td>14.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>195.0</td>\n",
              "      <td>0.011</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.8</td>\n",
              "      <td>168.6</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.5</td>\n",
              "      <td>128.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>3.92</td>\n",
              "      <td>4.1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10.3</td>\n",
              "      <td>236.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>103.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>137.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>103.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>67.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>13.5</td>\n",
              "      <td>38.7</td>\n",
              "      <td>213.0</td>\n",
              "      <td>0.035</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103.0</td>\n",
              "      <td>11.77</td>\n",
              "      <td>69.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>45.2</td>\n",
              "      <td>2060.0</td>\n",
              "      <td>1491.0</td>\n",
              "      <td>0.723786</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.1</td>\n",
              "      <td>153.6</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.7</td>\n",
              "      <td>150.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>4.16</td>\n",
              "      <td>3.7</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.72</td>\n",
              "      <td>93.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>6.2</td>\n",
              "      <td>4.4</td>\n",
              "      <td>142.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>117.0</td>\n",
              "      <td>5.3</td>\n",
              "      <td>11.3</td>\n",
              "      <td>35.2</td>\n",
              "      <td>334.0</td>\n",
              "      <td>0.237</td>\n",
              "      <td>5.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.4</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>734.0</td>\n",
              "      <td>0.608119</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age  race  education  ...     fvc    fev1  fev1_fvc_ratio  Diabetes \n",
              "0          1   21     7        2.0  ...  3650.0  2846.0        0.779726        0.0\n",
              "1          0   21     1        2.0  ...  4327.0  3629.0        0.838687        0.0\n",
              "2          0   21     2        3.0  ...  4471.0  3725.0        0.833147        0.0\n",
              "3          0   21     1        2.0  ...  5161.0  4301.0        0.833366        0.0\n",
              "4          0   21     2        3.0  ...  6250.0  5168.0        0.826880        0.0\n",
              "...      ...  ...   ...        ...  ...     ...     ...             ...        ...\n",
              "5201       0   77     7        5.0  ...  3097.0  2249.0        0.726187        1.0\n",
              "5202       0   77     4        3.0  ...  2872.0  1716.0        0.597493        0.0\n",
              "5203       0   77     3        4.0  ...     0.0     0.0        0.000000        1.0\n",
              "5204       1   77     4        2.0  ...  2060.0  1491.0        0.723786        0.0\n",
              "5205       1   77     4        3.0  ...  1207.0   734.0        0.608119        1.0\n",
              "\n",
              "[5206 rows x 66 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J78MLWdgt78V",
        "outputId": "a4cdf9fb-7d73-47de-8b69-4c29aef60f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "data = pd.read_csv(r'filled_Noheader.csv')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>race</th>\n",
              "      <th>education</th>\n",
              "      <th>marital</th>\n",
              "      <th>income</th>\n",
              "      <th>household_size</th>\n",
              "      <th>insurance</th>\n",
              "      <th>private_insur</th>\n",
              "      <th>gen_health</th>\n",
              "      <th>asthma</th>\n",
              "      <th>chf</th>\n",
              "      <th>cad</th>\n",
              "      <th>mi</th>\n",
              "      <th>cva</th>\n",
              "      <th>copd</th>\n",
              "      <th>cancer</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>depression</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>smoker</th>\n",
              "      <th>drinks_day</th>\n",
              "      <th>weight_kg</th>\n",
              "      <th>height_cm</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>dia_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>alb</th>\n",
              "      <th>alt</th>\n",
              "      <th>ast</th>\n",
              "      <th>alk_phos</th>\n",
              "      <th>bun</th>\n",
              "      <th>ca</th>\n",
              "      <th>cpk</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>bicarb</th>\n",
              "      <th>cr</th>\n",
              "      <th>glucose</th>\n",
              "      <th>iron</th>\n",
              "      <th>ldh</th>\n",
              "      <th>phos</th>\n",
              "      <th>t_bilirubin</th>\n",
              "      <th>t_protein</th>\n",
              "      <th>u_acid</th>\n",
              "      <th>sodium</th>\n",
              "      <th>potassium</th>\n",
              "      <th>chloride</th>\n",
              "      <th>glob</th>\n",
              "      <th>trigs</th>\n",
              "      <th>wbc</th>\n",
              "      <th>hgb</th>\n",
              "      <th>hct</th>\n",
              "      <th>platelets</th>\n",
              "      <th>s_cotinine</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>insulin</th>\n",
              "      <th>hdl</th>\n",
              "      <th>ldl_chol</th>\n",
              "      <th>grip_strength</th>\n",
              "      <th>fvc</th>\n",
              "      <th>fev1</th>\n",
              "      <th>fev1_fvc_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>50.8</td>\n",
              "      <td>167.1</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>96</td>\n",
              "      <td>50</td>\n",
              "      <td>11.77</td>\n",
              "      <td>4.4</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>44</td>\n",
              "      <td>7</td>\n",
              "      <td>8.8</td>\n",
              "      <td>35</td>\n",
              "      <td>118</td>\n",
              "      <td>25</td>\n",
              "      <td>0.44</td>\n",
              "      <td>82</td>\n",
              "      <td>165</td>\n",
              "      <td>75</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>138</td>\n",
              "      <td>3.4</td>\n",
              "      <td>105</td>\n",
              "      <td>2.9</td>\n",
              "      <td>54</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.7</td>\n",
              "      <td>36.1</td>\n",
              "      <td>157</td>\n",
              "      <td>0.654</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88</td>\n",
              "      <td>7.27</td>\n",
              "      <td>47</td>\n",
              "      <td>49</td>\n",
              "      <td>50.3</td>\n",
              "      <td>3650</td>\n",
              "      <td>2846</td>\n",
              "      <td>0.779726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>72.8</td>\n",
              "      <td>167.5</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.7</td>\n",
              "      <td>110</td>\n",
              "      <td>60</td>\n",
              "      <td>2.37</td>\n",
              "      <td>4.5</td>\n",
              "      <td>25</td>\n",
              "      <td>24</td>\n",
              "      <td>112</td>\n",
              "      <td>13</td>\n",
              "      <td>9.6</td>\n",
              "      <td>214</td>\n",
              "      <td>172</td>\n",
              "      <td>27</td>\n",
              "      <td>0.81</td>\n",
              "      <td>81</td>\n",
              "      <td>119</td>\n",
              "      <td>137</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.2</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.8</td>\n",
              "      <td>137</td>\n",
              "      <td>3.5</td>\n",
              "      <td>102</td>\n",
              "      <td>2.8</td>\n",
              "      <td>83</td>\n",
              "      <td>6.9</td>\n",
              "      <td>15.1</td>\n",
              "      <td>44.4</td>\n",
              "      <td>226</td>\n",
              "      <td>0.221</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88</td>\n",
              "      <td>12.01</td>\n",
              "      <td>40</td>\n",
              "      <td>112</td>\n",
              "      <td>90.1</td>\n",
              "      <td>4327</td>\n",
              "      <td>3629</td>\n",
              "      <td>0.838687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>81.0</td>\n",
              "      <td>165.6</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.3</td>\n",
              "      <td>114</td>\n",
              "      <td>72</td>\n",
              "      <td>3.73</td>\n",
              "      <td>4.5</td>\n",
              "      <td>23</td>\n",
              "      <td>21</td>\n",
              "      <td>103</td>\n",
              "      <td>10</td>\n",
              "      <td>9.3</td>\n",
              "      <td>73</td>\n",
              "      <td>168</td>\n",
              "      <td>25</td>\n",
              "      <td>0.82</td>\n",
              "      <td>87</td>\n",
              "      <td>68</td>\n",
              "      <td>112</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>7.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>138</td>\n",
              "      <td>3.5</td>\n",
              "      <td>104</td>\n",
              "      <td>3.0</td>\n",
              "      <td>256</td>\n",
              "      <td>8.2</td>\n",
              "      <td>14.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>266</td>\n",
              "      <td>0.011</td>\n",
              "      <td>5.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>72.7</td>\n",
              "      <td>4471</td>\n",
              "      <td>3725</td>\n",
              "      <td>0.833147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>56.9</td>\n",
              "      <td>178.3</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.1</td>\n",
              "      <td>108</td>\n",
              "      <td>62</td>\n",
              "      <td>3.74</td>\n",
              "      <td>4.8</td>\n",
              "      <td>18</td>\n",
              "      <td>23</td>\n",
              "      <td>65</td>\n",
              "      <td>10</td>\n",
              "      <td>9.5</td>\n",
              "      <td>151</td>\n",
              "      <td>144</td>\n",
              "      <td>26</td>\n",
              "      <td>0.73</td>\n",
              "      <td>91</td>\n",
              "      <td>63</td>\n",
              "      <td>87</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.9</td>\n",
              "      <td>136</td>\n",
              "      <td>3.6</td>\n",
              "      <td>102</td>\n",
              "      <td>2.6</td>\n",
              "      <td>57</td>\n",
              "      <td>6.6</td>\n",
              "      <td>14.7</td>\n",
              "      <td>43.0</td>\n",
              "      <td>206</td>\n",
              "      <td>16.300</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95</td>\n",
              "      <td>3.60</td>\n",
              "      <td>55</td>\n",
              "      <td>73</td>\n",
              "      <td>86.6</td>\n",
              "      <td>5161</td>\n",
              "      <td>4301</td>\n",
              "      <td>0.833366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>101.2</td>\n",
              "      <td>181.9</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.6</td>\n",
              "      <td>134</td>\n",
              "      <td>64</td>\n",
              "      <td>3.13</td>\n",
              "      <td>4.3</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>55</td>\n",
              "      <td>9</td>\n",
              "      <td>9.4</td>\n",
              "      <td>250</td>\n",
              "      <td>104</td>\n",
              "      <td>28</td>\n",
              "      <td>1.07</td>\n",
              "      <td>89</td>\n",
              "      <td>121</td>\n",
              "      <td>104</td>\n",
              "      <td>4.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>7.2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>142</td>\n",
              "      <td>4.7</td>\n",
              "      <td>104</td>\n",
              "      <td>2.9</td>\n",
              "      <td>70</td>\n",
              "      <td>7.8</td>\n",
              "      <td>15.6</td>\n",
              "      <td>45.1</td>\n",
              "      <td>306</td>\n",
              "      <td>212.000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95</td>\n",
              "      <td>14.58</td>\n",
              "      <td>39</td>\n",
              "      <td>55</td>\n",
              "      <td>94.4</td>\n",
              "      <td>6250</td>\n",
              "      <td>5168</td>\n",
              "      <td>0.826880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>85.6</td>\n",
              "      <td>161.5</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.9</td>\n",
              "      <td>130</td>\n",
              "      <td>64</td>\n",
              "      <td>11.43</td>\n",
              "      <td>4.2</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>50</td>\n",
              "      <td>14</td>\n",
              "      <td>8.9</td>\n",
              "      <td>198</td>\n",
              "      <td>171</td>\n",
              "      <td>22</td>\n",
              "      <td>0.73</td>\n",
              "      <td>126</td>\n",
              "      <td>67</td>\n",
              "      <td>119</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.6</td>\n",
              "      <td>138</td>\n",
              "      <td>3.9</td>\n",
              "      <td>107</td>\n",
              "      <td>2.7</td>\n",
              "      <td>130</td>\n",
              "      <td>6.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>41.8</td>\n",
              "      <td>205</td>\n",
              "      <td>0.269</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134</td>\n",
              "      <td>19.13</td>\n",
              "      <td>45</td>\n",
              "      <td>92</td>\n",
              "      <td>65.2</td>\n",
              "      <td>3097</td>\n",
              "      <td>2249</td>\n",
              "      <td>0.726187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>104.6</td>\n",
              "      <td>178.3</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>10.4</td>\n",
              "      <td>29.6</td>\n",
              "      <td>141</td>\n",
              "      <td>143.000</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2872</td>\n",
              "      <td>1716</td>\n",
              "      <td>0.597493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>39.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>136</td>\n",
              "      <td>62</td>\n",
              "      <td>33.20</td>\n",
              "      <td>3.6</td>\n",
              "      <td>32</td>\n",
              "      <td>28</td>\n",
              "      <td>61</td>\n",
              "      <td>18</td>\n",
              "      <td>8.9</td>\n",
              "      <td>94</td>\n",
              "      <td>197</td>\n",
              "      <td>24</td>\n",
              "      <td>0.98</td>\n",
              "      <td>101</td>\n",
              "      <td>123</td>\n",
              "      <td>161</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.2</td>\n",
              "      <td>138</td>\n",
              "      <td>3.7</td>\n",
              "      <td>104</td>\n",
              "      <td>3.9</td>\n",
              "      <td>169</td>\n",
              "      <td>10.7</td>\n",
              "      <td>14.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>195</td>\n",
              "      <td>0.011</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>103.8</td>\n",
              "      <td>168.6</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.5</td>\n",
              "      <td>128</td>\n",
              "      <td>74</td>\n",
              "      <td>3.92</td>\n",
              "      <td>4.1</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>80</td>\n",
              "      <td>14</td>\n",
              "      <td>10.3</td>\n",
              "      <td>236</td>\n",
              "      <td>181</td>\n",
              "      <td>23</td>\n",
              "      <td>0.95</td>\n",
              "      <td>103</td>\n",
              "      <td>69</td>\n",
              "      <td>138</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>137</td>\n",
              "      <td>3.9</td>\n",
              "      <td>103</td>\n",
              "      <td>3.3</td>\n",
              "      <td>67</td>\n",
              "      <td>4.3</td>\n",
              "      <td>13.5</td>\n",
              "      <td>38.7</td>\n",
              "      <td>213</td>\n",
              "      <td>0.035</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103</td>\n",
              "      <td>11.77</td>\n",
              "      <td>69</td>\n",
              "      <td>109</td>\n",
              "      <td>45.2</td>\n",
              "      <td>2060</td>\n",
              "      <td>1491</td>\n",
              "      <td>0.723786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>1</td>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>82.1</td>\n",
              "      <td>153.6</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.7</td>\n",
              "      <td>150</td>\n",
              "      <td>78</td>\n",
              "      <td>4.16</td>\n",
              "      <td>3.7</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>84</td>\n",
              "      <td>8</td>\n",
              "      <td>9.0</td>\n",
              "      <td>128</td>\n",
              "      <td>223</td>\n",
              "      <td>28</td>\n",
              "      <td>0.72</td>\n",
              "      <td>93</td>\n",
              "      <td>56</td>\n",
              "      <td>161</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>6.2</td>\n",
              "      <td>4.4</td>\n",
              "      <td>142</td>\n",
              "      <td>4.0</td>\n",
              "      <td>104</td>\n",
              "      <td>2.5</td>\n",
              "      <td>117</td>\n",
              "      <td>5.3</td>\n",
              "      <td>11.3</td>\n",
              "      <td>35.2</td>\n",
              "      <td>334</td>\n",
              "      <td>0.237</td>\n",
              "      <td>5.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>57.4</td>\n",
              "      <td>1207</td>\n",
              "      <td>734</td>\n",
              "      <td>0.608119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 65 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  age  race  education  ...  grip_strength   fvc  fev1  fev1_fvc_ratio\n",
              "0          1   21     7          2  ...           50.3  3650  2846        0.779726\n",
              "1          0   21     1          2  ...           90.1  4327  3629        0.838687\n",
              "2          0   21     2          3  ...           72.7  4471  3725        0.833147\n",
              "3          0   21     1          2  ...           86.6  5161  4301        0.833366\n",
              "4          0   21     2          3  ...           94.4  6250  5168        0.826880\n",
              "...      ...  ...   ...        ...  ...            ...   ...   ...             ...\n",
              "5201       0   77     7          5  ...           65.2  3097  2249        0.726187\n",
              "5202       0   77     4          3  ...            0.0  2872  1716        0.597493\n",
              "5203       0   77     3          4  ...            0.0     0     0        0.000000\n",
              "5204       1   77     4          2  ...           45.2  2060  1491        0.723786\n",
              "5205       1   77     4          3  ...           57.4  1207   734        0.608119\n",
              "\n",
              "[5206 rows x 65 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pYKUVNOtNxd",
        "outputId": "3eab77ff-7b7c-4164-e218-1cb7ee9ed8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print ('\\n Initial features: ', data.columns.tolist() )\n",
        "\n",
        "# number of selected features\n",
        "print ('\\n Number of selected features:')\n",
        "print (boruta_selector.n_features_)\n",
        "feature_df = pd.DataFrame(data.columns.tolist(), columns=['features'])\n",
        "\n",
        "feature_df['rank']=boruta_selector.ranking_\n",
        "feature_df = feature_df.sort_values('rank', ascending=True).reset_index(drop=True)\n",
        "print ('\\n Top %d features:' % boruta_selector.n_features_)\n",
        "print (feature_df.head(boruta_selector.n_features_))\n",
        "feature_df.to_csv('boruta-feature-ranking.csv', index=False)\n",
        "\n",
        "# check ranking of features\n",
        "print ('\\n Feature ranking:')\n",
        "print (boruta_selector.ranking_)\n",
        "\n",
        "# check selected features\n",
        "print ('\\n Selected features:')\n",
        "print (boruta_selector.support_)\n",
        "\n",
        "# check weak features\n",
        "print ('\\n Support for weak features:')\n",
        "print (boruta_selector.support_weak_)\n",
        "\n",
        "selected = data.columns[boruta_selector.support_]\n",
        "train = data[selected]\n",
        "data['Outcome'] = y\n",
        "train.to_csv('Borutafiltered.csv',index=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Initial features:  ['gender', 'age', 'race', 'education', 'marital', 'income', 'household_size', 'insurance', 'private_insur', 'gen_health', 'asthma', 'chf', 'cad', 'mi', 'cva', 'copd', 'cancer', 'diabetes', 'depression', 'hypertension', 'smoker', 'drinks_day', 'weight_kg', 'height_cm', 'bmi', 'waist_cm', 'sys_bp', 'dia_bp', 'alb_cr_ratio', 'alb', 'alt', 'ast', 'alk_phos', 'bun', 'ca', 'cpk', 't_chol', 'bicarb', 'cr', 'glucose', 'iron', 'ldh', 'phos', 't_bilirubin', 't_protein', 'u_acid', 'sodium', 'potassium', 'chloride', 'glob', 'trigs', 'wbc', 'hgb', 'hct', 'platelets', 's_cotinine', 'a1c', 'glucose.1', 'insulin', 'hdl', 'ldl_chol', 'grip_strength', 'fvc', 'fev1', 'fev1_fvc_ratio']\n",
            "\n",
            " Number of selected features:\n",
            "27\n",
            "\n",
            " Top 27 features:\n",
            "        features  rank\n",
            "0       alk_phos     1\n",
            "1             cr     1\n",
            "2            bun     1\n",
            "3           fev1     1\n",
            "4        glucose     1\n",
            "5   alb_cr_ratio     1\n",
            "6         sys_bp     1\n",
            "7       waist_cm     1\n",
            "8            bmi     1\n",
            "9      weight_kg     1\n",
            "10  hypertension     1\n",
            "11      diabetes     1\n",
            "12          glob     1\n",
            "13         trigs     1\n",
            "14      chloride     1\n",
            "15           hgb     1\n",
            "16           age     1\n",
            "17           fvc     1\n",
            "18           hdl     1\n",
            "19           wbc     1\n",
            "20     glucose.1     1\n",
            "21    gen_health     1\n",
            "22       insulin     1\n",
            "23           a1c     1\n",
            "24     platelets     1\n",
            "25           hct     1\n",
            "26        t_chol     1\n",
            "\n",
            " Feature ranking:\n",
            "[30  1 26 21 21  4 26 34 32  1 39 28 31 34 36 37 33  1 29  1 38 25  1  6\n",
            "  1  1  1 17  1  7 12 15  1  1 14 10  1 23  1  1 10  7 20 23 19  3 16  2\n",
            "  1  1  1  1  1  1  1 18  1  1  1  1  4  9  1  1 12]\n",
            "\n",
            " Selected features:\n",
            "[False  True False False False False False False False  True False False\n",
            " False False False False False  True False  True False False  True False\n",
            "  True  True  True False  True False False False  True  True False False\n",
            "  True False  True  True False False False False False False False False\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            " False False  True  True False]\n",
            "\n",
            " Support for weak features:\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtOxuECrtabk",
        "outputId": "b0c722f6-37bf-4724-be52-753cee9eda73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "filtered = pd.read_csv(r'Borutafiltered.csv')\n",
        "filtered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gen_health</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>weight_kg</th>\n",
              "      <th>bmi</th>\n",
              "      <th>waist_cm</th>\n",
              "      <th>sys_bp</th>\n",
              "      <th>alb_cr_ratio</th>\n",
              "      <th>alk_phos</th>\n",
              "      <th>bun</th>\n",
              "      <th>t_chol</th>\n",
              "      <th>cr</th>\n",
              "      <th>glucose</th>\n",
              "      <th>chloride</th>\n",
              "      <th>glob</th>\n",
              "      <th>trigs</th>\n",
              "      <th>wbc</th>\n",
              "      <th>hgb</th>\n",
              "      <th>hct</th>\n",
              "      <th>platelets</th>\n",
              "      <th>a1c</th>\n",
              "      <th>glucose.1</th>\n",
              "      <th>insulin</th>\n",
              "      <th>hdl</th>\n",
              "      <th>fvc</th>\n",
              "      <th>fev1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>50.8</td>\n",
              "      <td>18.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>96</td>\n",
              "      <td>11.77</td>\n",
              "      <td>44</td>\n",
              "      <td>7</td>\n",
              "      <td>118</td>\n",
              "      <td>0.44</td>\n",
              "      <td>82</td>\n",
              "      <td>105</td>\n",
              "      <td>2.9</td>\n",
              "      <td>54</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.7</td>\n",
              "      <td>36.1</td>\n",
              "      <td>157</td>\n",
              "      <td>5.0</td>\n",
              "      <td>88</td>\n",
              "      <td>7.27</td>\n",
              "      <td>47</td>\n",
              "      <td>3650</td>\n",
              "      <td>2846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>72.8</td>\n",
              "      <td>25.9</td>\n",
              "      <td>93.7</td>\n",
              "      <td>110</td>\n",
              "      <td>2.37</td>\n",
              "      <td>112</td>\n",
              "      <td>13</td>\n",
              "      <td>172</td>\n",
              "      <td>0.81</td>\n",
              "      <td>81</td>\n",
              "      <td>102</td>\n",
              "      <td>2.8</td>\n",
              "      <td>83</td>\n",
              "      <td>6.9</td>\n",
              "      <td>15.1</td>\n",
              "      <td>44.4</td>\n",
              "      <td>226</td>\n",
              "      <td>5.2</td>\n",
              "      <td>88</td>\n",
              "      <td>12.01</td>\n",
              "      <td>40</td>\n",
              "      <td>4327</td>\n",
              "      <td>3629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>81.0</td>\n",
              "      <td>29.5</td>\n",
              "      <td>102.3</td>\n",
              "      <td>114</td>\n",
              "      <td>3.73</td>\n",
              "      <td>103</td>\n",
              "      <td>10</td>\n",
              "      <td>168</td>\n",
              "      <td>0.82</td>\n",
              "      <td>87</td>\n",
              "      <td>104</td>\n",
              "      <td>3.0</td>\n",
              "      <td>256</td>\n",
              "      <td>8.2</td>\n",
              "      <td>14.4</td>\n",
              "      <td>41.3</td>\n",
              "      <td>266</td>\n",
              "      <td>5.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38</td>\n",
              "      <td>4471</td>\n",
              "      <td>3725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>56.9</td>\n",
              "      <td>17.9</td>\n",
              "      <td>69.1</td>\n",
              "      <td>108</td>\n",
              "      <td>3.74</td>\n",
              "      <td>65</td>\n",
              "      <td>10</td>\n",
              "      <td>144</td>\n",
              "      <td>0.73</td>\n",
              "      <td>91</td>\n",
              "      <td>102</td>\n",
              "      <td>2.6</td>\n",
              "      <td>57</td>\n",
              "      <td>6.6</td>\n",
              "      <td>14.7</td>\n",
              "      <td>43.0</td>\n",
              "      <td>206</td>\n",
              "      <td>5.1</td>\n",
              "      <td>95</td>\n",
              "      <td>3.60</td>\n",
              "      <td>55</td>\n",
              "      <td>5161</td>\n",
              "      <td>4301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>101.2</td>\n",
              "      <td>30.6</td>\n",
              "      <td>101.6</td>\n",
              "      <td>134</td>\n",
              "      <td>3.13</td>\n",
              "      <td>55</td>\n",
              "      <td>9</td>\n",
              "      <td>104</td>\n",
              "      <td>1.07</td>\n",
              "      <td>89</td>\n",
              "      <td>104</td>\n",
              "      <td>2.9</td>\n",
              "      <td>70</td>\n",
              "      <td>7.8</td>\n",
              "      <td>15.6</td>\n",
              "      <td>45.1</td>\n",
              "      <td>306</td>\n",
              "      <td>6.0</td>\n",
              "      <td>95</td>\n",
              "      <td>14.58</td>\n",
              "      <td>39</td>\n",
              "      <td>6250</td>\n",
              "      <td>5168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>85.6</td>\n",
              "      <td>32.8</td>\n",
              "      <td>115.9</td>\n",
              "      <td>130</td>\n",
              "      <td>11.43</td>\n",
              "      <td>50</td>\n",
              "      <td>14</td>\n",
              "      <td>171</td>\n",
              "      <td>0.73</td>\n",
              "      <td>126</td>\n",
              "      <td>107</td>\n",
              "      <td>2.7</td>\n",
              "      <td>130</td>\n",
              "      <td>6.1</td>\n",
              "      <td>14.2</td>\n",
              "      <td>41.8</td>\n",
              "      <td>205</td>\n",
              "      <td>6.5</td>\n",
              "      <td>134</td>\n",
              "      <td>19.13</td>\n",
              "      <td>45</td>\n",
              "      <td>3097</td>\n",
              "      <td>2249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>77</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>104.6</td>\n",
              "      <td>32.9</td>\n",
              "      <td>122.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1375.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>10.4</td>\n",
              "      <td>29.6</td>\n",
              "      <td>141</td>\n",
              "      <td>6.2</td>\n",
              "      <td>98</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2872</td>\n",
              "      <td>1716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>77</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>99.0</td>\n",
              "      <td>39.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>136</td>\n",
              "      <td>33.20</td>\n",
              "      <td>61</td>\n",
              "      <td>18</td>\n",
              "      <td>197</td>\n",
              "      <td>0.98</td>\n",
              "      <td>101</td>\n",
              "      <td>104</td>\n",
              "      <td>3.9</td>\n",
              "      <td>169</td>\n",
              "      <td>10.7</td>\n",
              "      <td>14.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>195</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>103.8</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119.5</td>\n",
              "      <td>128</td>\n",
              "      <td>3.92</td>\n",
              "      <td>80</td>\n",
              "      <td>14</td>\n",
              "      <td>181</td>\n",
              "      <td>0.95</td>\n",
              "      <td>103</td>\n",
              "      <td>103</td>\n",
              "      <td>3.3</td>\n",
              "      <td>67</td>\n",
              "      <td>4.3</td>\n",
              "      <td>13.5</td>\n",
              "      <td>38.7</td>\n",
              "      <td>213</td>\n",
              "      <td>6.2</td>\n",
              "      <td>103</td>\n",
              "      <td>11.77</td>\n",
              "      <td>69</td>\n",
              "      <td>2060</td>\n",
              "      <td>1491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>77</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>82.1</td>\n",
              "      <td>34.8</td>\n",
              "      <td>104.7</td>\n",
              "      <td>150</td>\n",
              "      <td>4.16</td>\n",
              "      <td>84</td>\n",
              "      <td>8</td>\n",
              "      <td>223</td>\n",
              "      <td>0.72</td>\n",
              "      <td>93</td>\n",
              "      <td>104</td>\n",
              "      <td>2.5</td>\n",
              "      <td>117</td>\n",
              "      <td>5.3</td>\n",
              "      <td>11.3</td>\n",
              "      <td>35.2</td>\n",
              "      <td>334</td>\n",
              "      <td>5.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>51</td>\n",
              "      <td>1207</td>\n",
              "      <td>734</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  gen_health  diabetes  hypertension  ...  insulin  hdl   fvc  fev1\n",
              "0      21           3         2             2  ...     7.27   47  3650  2846\n",
              "1      21           3         2             2  ...    12.01   40  4327  3629\n",
              "2      21           3         2             2  ...     0.00   38  4471  3725\n",
              "3      21           4         2             2  ...     3.60   55  5161  4301\n",
              "4      21           2         2             2  ...    14.58   39  6250  5168\n",
              "...   ...         ...       ...           ...  ...      ...  ...   ...   ...\n",
              "5201   77           2         1             2  ...    19.13   45  3097  2249\n",
              "5202   77           4         1             1  ...     0.00    0  2872  1716\n",
              "5203   77           5         1             1  ...     0.00   38     0     0\n",
              "5204   77           3         1             1  ...    11.77   69  2060  1491\n",
              "5205   77           3         1             1  ...     0.00   51  1207   734\n",
              "\n",
              "[5206 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBDzUARtclF",
        "outputId": "2bddce09-dd0f-4cf3-97a5-eebde5a3c3ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "new_x = filtered.iloc[:, 0:26].values\n",
        "new_x\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.100e+01, 3.000e+00, 2.000e+00, ..., 7.270e+00, 4.700e+01,\n",
              "        3.650e+03],\n",
              "       [2.100e+01, 3.000e+00, 2.000e+00, ..., 1.201e+01, 4.000e+01,\n",
              "        4.327e+03],\n",
              "       [2.100e+01, 3.000e+00, 2.000e+00, ..., 0.000e+00, 3.800e+01,\n",
              "        4.471e+03],\n",
              "       ...,\n",
              "       [7.700e+01, 5.000e+00, 1.000e+00, ..., 0.000e+00, 3.800e+01,\n",
              "        0.000e+00],\n",
              "       [7.700e+01, 3.000e+00, 1.000e+00, ..., 1.177e+01, 6.900e+01,\n",
              "        2.060e+03],\n",
              "       [7.700e+01, 3.000e+00, 1.000e+00, ..., 0.000e+00, 5.100e+01,\n",
              "        1.207e+03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XprUBYWteGE"
      },
      "source": [
        "\n",
        "X_t, X_val, y_t, y_val = train_test_split(new_x, y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7HMWcYGtfjw"
      },
      "source": [
        "rf2 = RandomForestClassifier( n_estimators=500, max_depth=6)\n",
        "rf2.fit(X_t, y_t)\n",
        "y_pred = rf2.predict(X_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-3ibbLz3iq3",
        "outputId": "07aee414-9619-4188-fcb8-b56f105adb47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eihiIiKQvwqI"
      },
      "source": [
        "pickle.dump(rf2, open('BorutaRF.pkl', 'wb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7C-7OBOv3Dy",
        "outputId": "f25086af-0b87-4e6a-9d5f-4958257fe5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(classification_report(y_val, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      1111\n",
            "         1.0       0.95      0.94      0.95       191\n",
            "\n",
            "    accuracy                           0.98      1302\n",
            "   macro avg       0.97      0.97      0.97      1302\n",
            "weighted avg       0.98      0.98      0.98      1302\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVytPKv2zjDX"
      },
      "source": [
        "# LASSO + CrossVal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARwNRj7SxT8T"
      },
      "source": [
        "from sklearn.linear_model import Lasso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmMrVORD0c1_"
      },
      "source": [
        "lasso= Lasso()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcCuQhW64R8i"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "parameters ={'alpha':[1]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TBjLARB43tK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDQQFq2o4KLQ"
      },
      "source": [
        "lasso_regressor = GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWiJ86Q53DQA"
      },
      "source": [
        "y_pred=lasso_regressor.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtwQjXbg2lY4",
        "outputId": "183946bc-2ac6-445e-cf8f-e45127077d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "lasso_regressor.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                             max_iter=1000, normalize=False, positive=False,\n",
              "                             precompute=False, random_state=None,\n",
              "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None, param_grid={'alpha': [1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlqnGMaU5Njs",
        "outputId": "3fa619f7-fe53-4146-abff-39aecf71bef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lasso_regressor.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.12266420014181253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T2vkuQXpZKr"
      },
      "source": [
        "y_lasso=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AWCpq_gpcT8",
        "outputId": "86f7397a-4cdb-41f8-e723-c6bc5b528db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y_pred:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    y_lasso.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    y_lasso.append(add)\n",
        "\n",
        "y_lasso\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99vIwKNu22Nv",
        "outputId": "1316519d-ed58-4d96-8985-b270c8fe7cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "print(classification_report(y_test, y_lasso))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92       886\n",
            "           1       0.00      0.00      0.00       155\n",
            "\n",
            "    accuracy                           0.85      1041\n",
            "   macro avg       0.43      0.50      0.46      1041\n",
            "weighted avg       0.72      0.85      0.78      1041\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBYx4xLq3dDE",
        "outputId": "466acce8-442f-4e9a-c03a-79898d9baba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1431316, 0.1431316, 0.1431316, ..., 0.1431316, 0.1431316,\n",
              "       0.1431316])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABCgANSs59xC"
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8M4FCEB6E2i",
        "outputId": "45b8e832-dbe2-4d03-bebf-f0093cff1091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "pip install sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FvJZ6sH6Nku"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FMLHE1P6tMY"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTbQ_R2Z3Vyy",
        "outputId": "2dec3cf7-d45c-47c4-b10a-0da37ce3d9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "X_train, X_test , y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=1)\n",
        "\n",
        "lassocv = LassoCV(alphas=None, cv=10, max_iter=100000, normalize=True)\n",
        "lassocv.fit(X_train, y_train)\n",
        "lasso.set_params(alpha=lassocv.alpha_)\n",
        "print(\"Alpha=\", lassocv.alpha_)\n",
        "lasso.fit(X_train, y_train)\n",
        "print(\"mse = \",mean_squared_error(y_test, lasso.predict(X_test)))\n",
        "y_pred=lassocv.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alpha= 8.592036019209137e-05\n",
            "mse =  0.0508749742523064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.36132967438843, tolerance: 0.03145378409527467\n",
            "  positive)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYk2RyNL56Lz",
        "outputId": "d1112668-bd1d-42e8-c5e7-7873dbba1e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ_ipbG49jGV",
        "outputId": "9e0c975f-f109-43df-b7ae-897af01910c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7810"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvjzl39e8Z4i"
      },
      "source": [
        "y_new=[]\n",
        "i=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KXgPrP070Xy"
      },
      "source": [
        "for i in y_pred:\n",
        "  if i>0.5:\n",
        "      add=1\n",
        "      y_new.append(add)\n",
        "  else:\n",
        "      add=0\n",
        "      y_new.append(add)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_f0n2T38so0"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0NjvibB9Ffk"
      },
      "source": [
        "y_pred=np.asarray(y_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMAC_F0-9Ojd"
      },
      "source": [
        "#print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhRIG3cF9Rw7"
      },
      "source": [
        "for i in y_pred:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    y_pred_new.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    y_pred_new.append(add)\n",
        "\n",
        "y_pred_new\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2_XUvod93HU"
      },
      "source": [
        "# LOGISTIC REGRESSION + RIDGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQU0u5oP97lW"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "def ridge_regression(data, predictors, alpha, models_to_plot={}):\n",
        "    #Fit the model\n",
        "    ridgereg = Ridge(alpha=alpha,normalize=True)\n",
        "    ridgereg.fit(data[predictors],data['y'])\n",
        "    y_pred = ridgereg.predict(data[predictors])\n",
        "    \n",
        "    #Check if a plot is to be made for the entered alpha\n",
        "    if alpha in models_to_plot:\n",
        "        plt.subplot(models_to_plot[alpha])\n",
        "        plt.tight_layout()\n",
        "        plt.plot(data['x'],y_pred)\n",
        "        plt.plot(data['x'],data['y'],'.')\n",
        "        plt.title('Plot for alpha: %.3g'%alpha)\n",
        "    \n",
        "    #Return the result in pre-defined format\n",
        "    rss = sum((y_pred-data['y'])**2)\n",
        "    ret = [rss]\n",
        "    ret.extend([ridgereg.intercept_])\n",
        "    ret.extend(ridgereg.coef_)\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNkbxZvHF68k",
        "outputId": "454814da-468f-47e3-b818-323a6888fd3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "clf = Ridge(alpha=1.0)\n",
        "clf.fit(x_train, y_train)\n",
        "Ridge()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "      normalize=False, random_state=None, solver='auto', tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S3DwCzlGovn"
      },
      "source": [
        "y_predict=clf.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46H0r64ystaT"
      },
      "source": [
        "y_ridge=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkDLBwVcssTw",
        "outputId": "8fca4dd9-e6fc-48f4-8dbd-6206d254d766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y_predict:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    y_ridge.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    y_ridge.append(add)\n",
        "\n",
        "y_ridge\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1lYwVheG7cH",
        "outputId": "a69f8c01-57f7-4576-a5ce-6de5e323fd69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(y_test,y_ridge)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9173871277617676"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOi2KtOboqP0"
      },
      "source": [
        "Regularization techniques are used to deal with overfitting and when the dataset is large.\n",
        "So, Lasso and Ridge are not useful in our case.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTP99uoGHdps"
      },
      "source": [
        "# XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_nUNEPMo-Rc"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qsCblmaHhGh",
        "outputId": "36ba3d37-b357-46b1-9ed4-ffac9d9f8d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "\n",
        "\n",
        "train = x_train\n",
        "test = x_test\n",
        "\n",
        "# print(\"Train a Gradient Boosting model\")\n",
        "# clf = GradientBoostingClassifier(n_estimators=50, learning_rate=0.005, subsample=0.7,\n",
        "#                                      min_samples_leaf=10, max_depth=7, random_state=11)\n",
        "print(\"Train a Random Forest model\")\n",
        "clf = RandomForestClassifier(n_estimators=25)\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "print(\"Train a XGBoost model\")\n",
        "params = {\"objective\": \"reg:linear\",\n",
        "          \"eta\": 0.3,\n",
        "          \"max_depth\": 5,\n",
        "          \"min_child_weight\": 3,\n",
        "          \"silent\": 1,\n",
        "          \"subsample\": 0.7,\n",
        "          \"colsample_bytree\": 0.7,\n",
        "          \"seed\": 1}\n",
        "num_trees=250\n",
        "gbm = xgb.train(params, xgb.DMatrix(x_train, y_train), num_trees)\n",
        "\n",
        "print(\"Make predictions on the test set\")\n",
        "test_probs = (clf.predict_proba(x_test)[:,1] +\n",
        "              gbm.predict(xgb.DMatrix(x_test)))/2\n",
        "\n",
        "y_pred= clf.predict_proba(x_test)[:, 1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train a Random Forest model\n",
            "Train a XGBoost model\n",
            "Make predictions on the test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mVF70F-Jc7V",
        "outputId": "3cfcf85b-7ca9-4fbe-c19b-06f2f0505559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.92])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R-cV5nwRWZg"
      },
      "source": [
        "y_pred_new=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuaWB7m-pNOj",
        "outputId": "439211d2-0a81-4208-c192-fec418c33efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in y_pred:\n",
        "  if i>0.5:\n",
        "    add=1\n",
        "    y_pred_new.append(add)\n",
        "  elif i<0.5:\n",
        "    add=0\n",
        "    y_pred_new.append(add)\n",
        "\n",
        "y_pred_new\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1Jfa-vmpU5i",
        "outputId": "dd2281ef-f912-48f4-bbf3-cb24ef0a8eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(classification_report(y_test, y_pred_new))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       886\n",
            "           1       0.96      0.81      0.88       155\n",
            "\n",
            "    accuracy                           0.97      1041\n",
            "   macro avg       0.96      0.90      0.93      1041\n",
            "weighted avg       0.97      0.97      0.97      1041\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfoZWhlopj4k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUKXcgFbtFk_"
      },
      "source": [
        "# LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AbJOGHytP34"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbxvWb3Ltc8p"
      },
      "source": [
        "acc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td3fPhrqteQe",
        "outputId": "bea9e7fd-cadb-47f9-a112-344fd8bb9a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while acc<0.98:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "\n",
        "  LR = LogisticRegression()\n",
        "  LR.fit(x_train,y_train)\n",
        "  LR_pred = LR.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "  #print(classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, LR_pred)\n",
        "  print(acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.968299711815562\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9750240153698367\n",
            "0.9740634005763689\n",
            "0.9779058597502401\n",
            "0.9702209414024976\n",
            "0.968299711815562\n",
            "0.962536023054755\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.9779058597502401\n",
            "0.9702209414024976\n",
            "0.9644572526416907\n",
            "0.962536023054755\n",
            "0.9673390970220941\n",
            "0.9654178674351584\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9740634005763689\n",
            "0.9731027857829011\n",
            "0.9702209414024976\n",
            "0.9702209414024976\n",
            "0.9750240153698367\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9798270893371758\n",
            "0.9779058597502401\n",
            "0.9615754082612872\n",
            "0.9673390970220941\n",
            "0.9644572526416907\n",
            "0.9769452449567724\n",
            "0.9769452449567724\n",
            "0.9654178674351584\n",
            "0.9731027857829011\n",
            "0.9606147934678194\n",
            "0.9702209414024976\n",
            "0.968299711815562\n",
            "0.9615754082612872\n",
            "0.968299711815562\n",
            "0.9644572526416907\n",
            "0.9606147934678194\n",
            "0.9654178674351584\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9606147934678194\n",
            "0.9596541786743515\n",
            "0.9644572526416907\n",
            "0.9740634005763689\n",
            "0.9596541786743515\n",
            "0.9654178674351584\n",
            "0.9711815561959655\n",
            "0.9615754082612872\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9759846301633045\n",
            "0.968299711815562\n",
            "0.978866474543708\n",
            "0.9750240153698367\n",
            "0.9644572526416907\n",
            "0.9721421709894332\n",
            "0.9663784822286263\n",
            "0.9692603266090298\n",
            "0.9663784822286263\n",
            "0.9673390970220941\n",
            "0.9740634005763689\n",
            "0.9702209414024976\n",
            "0.9663784822286263\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9673390970220941\n",
            "0.9692603266090298\n",
            "0.9740634005763689\n",
            "0.9663784822286263\n",
            "0.9663784822286263\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.9731027857829011\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9673390970220941\n",
            "0.9750240153698367\n",
            "0.9606147934678194\n",
            "0.9663784822286263\n",
            "0.9634966378482228\n",
            "0.9634966378482228\n",
            "0.9673390970220941\n",
            "0.9673390970220941\n",
            "0.962536023054755\n",
            "0.968299711815562\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.962536023054755\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9711815561959655\n",
            "0.9731027857829011\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9615754082612872\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9702209414024976\n",
            "0.9702209414024976\n",
            "0.9615754082612872\n",
            "0.9644572526416907\n",
            "0.962536023054755\n",
            "0.9731027857829011\n",
            "0.9663784822286263\n",
            "0.9663784822286263\n",
            "0.962536023054755\n",
            "0.9644572526416907\n",
            "0.968299711815562\n",
            "0.9711815561959655\n",
            "0.9759846301633045\n",
            "0.962536023054755\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9731027857829011\n",
            "0.9711815561959655\n",
            "0.9663784822286263\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9711815561959655\n",
            "0.9779058597502401\n",
            "0.9673390970220941\n",
            "0.9606147934678194\n",
            "0.9606147934678194\n",
            "0.9711815561959655\n",
            "0.968299711815562\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.968299711815562\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9711815561959655\n",
            "0.9634966378482228\n",
            "0.962536023054755\n",
            "0.9692603266090298\n",
            "0.9711815561959655\n",
            "0.9731027857829011\n",
            "0.9644572526416907\n",
            "0.9721421709894332\n",
            "0.9692603266090298\n",
            "0.9721421709894332\n",
            "0.9731027857829011\n",
            "0.962536023054755\n",
            "0.9711815561959655\n",
            "0.9740634005763689\n",
            "0.9644572526416907\n",
            "0.9702209414024976\n",
            "0.9673390970220941\n",
            "0.9644572526416907\n",
            "0.9654178674351584\n",
            "0.9721421709894332\n",
            "0.9740634005763689\n",
            "0.9692603266090298\n",
            "0.9721421709894332\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9644572526416907\n",
            "0.9731027857829011\n",
            "0.9596541786743515\n",
            "0.9692603266090298\n",
            "0.9779058597502401\n",
            "0.968299711815562\n",
            "0.9702209414024976\n",
            "0.9731027857829011\n",
            "0.9740634005763689\n",
            "0.9644572526416907\n",
            "0.9654178674351584\n",
            "0.962536023054755\n",
            "0.9673390970220941\n",
            "0.9692603266090298\n",
            "0.9731027857829011\n",
            "0.9731027857829011\n",
            "0.9663784822286263\n",
            "0.9692603266090298\n",
            "0.9663784822286263\n",
            "0.9673390970220941\n",
            "0.962536023054755\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9644572526416907\n",
            "0.9663784822286263\n",
            "0.9634966378482228\n",
            "0.9711815561959655\n",
            "0.9721421709894332\n",
            "0.9769452449567724\n",
            "0.9692603266090298\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9740634005763689\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9702209414024976\n",
            "0.9615754082612872\n",
            "0.9711815561959655\n",
            "0.968299711815562\n",
            "0.9692603266090298\n",
            "0.962536023054755\n",
            "0.9702209414024976\n",
            "0.968299711815562\n",
            "0.968299711815562\n",
            "0.9615754082612872\n",
            "0.9663784822286263\n",
            "0.9663784822286263\n",
            "0.9759846301633045\n",
            "0.9567723342939481\n",
            "0.9692603266090298\n",
            "0.968299711815562\n",
            "0.9634966378482228\n",
            "0.9692603266090298\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.9759846301633045\n",
            "0.9759846301633045\n",
            "0.9673390970220941\n",
            "0.9596541786743515\n",
            "0.9731027857829011\n",
            "0.9644572526416907\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.9711815561959655\n",
            "0.9798270893371758\n",
            "0.9731027857829011\n",
            "0.9673390970220941\n",
            "0.9673390970220941\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9731027857829011\n",
            "0.9740634005763689\n",
            "0.9721421709894332\n",
            "0.9731027857829011\n",
            "0.9663784822286263\n",
            "0.968299711815562\n",
            "0.9654178674351584\n",
            "0.9606147934678194\n",
            "0.9731027857829011\n",
            "0.962536023054755\n",
            "0.9721421709894332\n",
            "0.9615754082612872\n",
            "0.9663784822286263\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9606147934678194\n",
            "0.968299711815562\n",
            "0.962536023054755\n",
            "0.9644572526416907\n",
            "0.968299711815562\n",
            "0.9644572526416907\n",
            "0.9615754082612872\n",
            "0.9663784822286263\n",
            "0.9759846301633045\n",
            "0.9654178674351584\n",
            "0.9692603266090298\n",
            "0.9731027857829011\n",
            "0.9731027857829011\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.9711815561959655\n",
            "0.9731027857829011\n",
            "0.9596541786743515\n",
            "0.968299711815562\n",
            "0.9634966378482228\n",
            "0.968299711815562\n",
            "0.962536023054755\n",
            "0.968299711815562\n",
            "0.9586935638808838\n",
            "0.9731027857829011\n",
            "0.9673390970220941\n",
            "0.9673390970220941\n",
            "0.968299711815562\n",
            "0.9750240153698367\n",
            "0.9634966378482228\n",
            "0.9721421709894332\n",
            "0.9654178674351584\n",
            "0.9673390970220941\n",
            "0.9577329490874159\n",
            "0.9702209414024976\n",
            "0.962536023054755\n",
            "0.9692603266090298\n",
            "0.9769452449567724\n",
            "0.9634966378482228\n",
            "0.9654178674351584\n",
            "0.9711815561959655\n",
            "0.9654178674351584\n",
            "0.9721421709894332\n",
            "0.9673390970220941\n",
            "0.9663784822286263\n",
            "0.9711815561959655\n",
            "0.9673390970220941\n",
            "0.968299711815562\n",
            "0.9692603266090298\n",
            "0.9615754082612872\n",
            "0.9711815561959655\n",
            "0.9663784822286263\n",
            "0.9711815561959655\n",
            "0.9721421709894332\n",
            "0.9673390970220941\n",
            "0.9692603266090298\n",
            "0.9692603266090298\n",
            "0.9769452449567724\n",
            "0.962536023054755\n",
            "0.9644572526416907\n",
            "0.9750240153698367\n",
            "0.9702209414024976\n",
            "0.962536023054755\n",
            "0.962536023054755\n",
            "0.9731027857829011\n",
            "0.9692603266090298\n",
            "0.9644572526416907\n",
            "0.9711815561959655\n",
            "0.968299711815562\n",
            "0.9673390970220941\n",
            "0.9692603266090298\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9779058597502401\n",
            "0.9721421709894332\n",
            "0.9702209414024976\n",
            "0.9721421709894332\n",
            "0.9779058597502401\n",
            "0.9750240153698367\n",
            "0.9750240153698367\n",
            "0.9634966378482228\n",
            "0.9663784822286263\n",
            "0.9702209414024976\n",
            "0.9692603266090298\n",
            "0.9663784822286263\n",
            "0.9721421709894332\n",
            "0.9759846301633045\n",
            "0.9740634005763689\n",
            "0.9692603266090298\n",
            "0.962536023054755\n",
            "0.9759846301633045\n",
            "0.9673390970220941\n",
            "0.9711815561959655\n",
            "0.9692603266090298\n",
            "0.9750240153698367\n",
            "0.9673390970220941\n",
            "0.9702209414024976\n",
            "0.9731027857829011\n",
            "0.9740634005763689\n",
            "0.968299711815562\n",
            "0.9615754082612872\n",
            "0.9663784822286263\n",
            "0.968299711815562\n",
            "0.9654178674351584\n",
            "0.978866474543708\n",
            "0.9731027857829011\n",
            "0.9634966378482228\n",
            "0.9567723342939481\n",
            "0.9654178674351584\n",
            "0.9731027857829011\n",
            "0.9634966378482228\n",
            "0.9692603266090298\n",
            "0.9731027857829011\n",
            "0.9596541786743515\n",
            "0.9711815561959655\n",
            "0.9759846301633045\n",
            "0.9702209414024976\n",
            "0.9702209414024976\n",
            "0.9673390970220941\n",
            "0.9634966378482228\n",
            "0.9817483189241114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wS321SetIHX",
        "outputId": "2ac29207-4a61-4f51-a6ee-c0cee4721950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "\n",
        "print(confusion_matrix(y_test, LR_pred))\n",
        "print(classification_report(y_test, LR_pred))\n",
        "print(accuracy_score(y_test, LR_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[884   6]\n",
            " [ 13 138]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       890\n",
            "           1       0.96      0.91      0.94       151\n",
            "\n",
            "    accuracy                           0.98      1041\n",
            "   macro avg       0.97      0.95      0.96      1041\n",
            "weighted avg       0.98      0.98      0.98      1041\n",
            "\n",
            "0.9817483189241114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlB_07RwtXmY"
      },
      "source": [
        "acc=0\n",
        "from sklearn.svm import SVC   # Support Vector Classifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y9uJMXnu0AE"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Mi6AR3u9Jb",
        "outputId": "047e382b-67b2-41c2-a368-e74dddb87147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while acc<0.90:\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, ynew, test_size=0.2)\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train)\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "\n",
        "  SVMclassifier = SVC()\n",
        "  SVMclassifier.fit(x_train, y_train)\n",
        "  y_pred = SVMclassifier.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "  #print(confusion_matrix(y_test, y_pred))\n",
        "  #print(classification_report(y_test, y_pred))\n",
        "  acc=accuracy_score(y_test, LR_pred)\n",
        "  print(acc)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7588856868395774\n",
            "0.7598463016330451\n",
            "0.7531219980787704\n",
            "0.7646493756003843\n",
            "0.7425552353506244\n",
            "0.7406340057636888\n",
            "0.7665706051873199\n",
            "0.7780979827089337\n",
            "0.7550432276657061\n",
            "0.7598463016330451\n",
            "0.7531219980787704\n",
            "0.7540826128722382\n",
            "0.7550432276657061\n",
            "0.7675312199807877\n",
            "0.7675312199807877\n",
            "0.7473583093179635\n",
            "0.7694524495677233\n",
            "0.765609990393852\n",
            "0.7636887608069164\n",
            "0.7627281460134486\n",
            "0.7329490874159462\n",
            "0.7531219980787704\n",
            "0.7569644572526417\n",
            "0.7560038424591738\n",
            "0.7579250720461095\n",
            "0.7713736791546589\n",
            "0.7531219980787704\n",
            "0.7617675312199808\n",
            "0.7732949087415946\n",
            "0.7665706051873199\n",
            "0.7588856868395774\n",
            "0.7627281460134486\n",
            "0.7665706051873199\n",
            "0.7694524495677233\n",
            "0.760806916426513\n",
            "0.7531219980787704\n",
            "0.7694524495677233\n",
            "0.7473583093179635\n",
            "0.7675312199807877\n",
            "0.7646493756003843\n",
            "0.7627281460134486\n",
            "0.7550432276657061\n",
            "0.7809798270893372\n",
            "0.7627281460134486\n",
            "0.7761767531219981\n",
            "0.7598463016330451\n",
            "0.729106628242075\n",
            "0.7627281460134486\n",
            "0.7713736791546589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-67956e01b9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mSVMclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mSVMclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVMclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GnbY323vZBo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}